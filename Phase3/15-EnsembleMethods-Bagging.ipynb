{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble Methods: Simple Averaging and Bootstrap Aggregating (aka Bagging)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- Use `sklearn` to build voting models\n",
    "- Describe the algorithm of bagging\n",
    "- Describe the differences among simple bagging, random forest, and extra trees algorithms\n",
    "- Implement bagging models in `sklearn`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Ensemble Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Because many heads are better than one!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<img width=50% src='images/captain_planet.jpg'/>\n",
    "\n",
    "> \"With our powers combined...\"\n",
    "\n",
    "Ensemble Methods take advantage of the \"wisdom of crowds\" where the average of multiple independent estimates is usually more consistently accurate than the individual estimates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Three Varieties, Three Levels of Randomization\n",
    "\n",
    "We'll talk about two kinds of ensemble methods today:\n",
    "\n",
    "1. **Simple Averaging**: Train multiple model, then average\n",
    "2. **Bagging**: aka *B*ootstrap *AGG*regation - letting each model only see part of the data to train, then aggregating the results\n",
    "    - For trees, we'll specifically focus on two bagging techniques:\n",
    "    1. **Random Forest**: Choose a random set of features at each decision point\n",
    "    2. **Extra Trees**: Choose a path at random!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Data Preparation for Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mpg</th>\n",
       "      <th>cylinders</th>\n",
       "      <th>cubicinches</th>\n",
       "      <th>hp</th>\n",
       "      <th>weightlbs</th>\n",
       "      <th>time-to-60</th>\n",
       "      <th>year</th>\n",
       "      <th>brand</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.0</td>\n",
       "      <td>8</td>\n",
       "      <td>350.0</td>\n",
       "      <td>165</td>\n",
       "      <td>4209.0</td>\n",
       "      <td>12</td>\n",
       "      <td>1972</td>\n",
       "      <td>US.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31.9</td>\n",
       "      <td>4</td>\n",
       "      <td>89.0</td>\n",
       "      <td>71</td>\n",
       "      <td>1925.0</td>\n",
       "      <td>14</td>\n",
       "      <td>1980</td>\n",
       "      <td>Europe.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17.0</td>\n",
       "      <td>8</td>\n",
       "      <td>302.0</td>\n",
       "      <td>140</td>\n",
       "      <td>3449.0</td>\n",
       "      <td>11</td>\n",
       "      <td>1971</td>\n",
       "      <td>US.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15.0</td>\n",
       "      <td>8</td>\n",
       "      <td>400.0</td>\n",
       "      <td>150</td>\n",
       "      <td>3761.0</td>\n",
       "      <td>10</td>\n",
       "      <td>1971</td>\n",
       "      <td>US.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30.5</td>\n",
       "      <td>4</td>\n",
       "      <td>98.0</td>\n",
       "      <td>63</td>\n",
       "      <td>2051.0</td>\n",
       "      <td>17</td>\n",
       "      <td>1978</td>\n",
       "      <td>US.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mpg   cylinders   cubicinches   hp   weightlbs   time-to-60   year  \\\n",
       "0  14.0           8         350.0  165      4209.0           12   1972   \n",
       "1  31.9           4          89.0   71      1925.0           14   1980   \n",
       "2  17.0           8         302.0  140      3449.0           11   1971   \n",
       "3  15.0           8         400.0  150      3761.0           10   1971   \n",
       "4  30.5           4          98.0   63      2051.0           17   1978   \n",
       "\n",
       "      brand  \n",
       "0       US.  \n",
       "1   Europe.  \n",
       "2       US.  \n",
       "3       US.  \n",
       "4       US.  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/cars.csv', na_values = ' ')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 261 entries, 0 to 260\n",
      "Data columns (total 8 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   mpg           261 non-null    float64\n",
      " 1    cylinders    261 non-null    int64  \n",
      " 2    cubicinches  259 non-null    float64\n",
      " 3    hp           261 non-null    int64  \n",
      " 4    weightlbs    258 non-null    float64\n",
      " 5    time-to-60   261 non-null    int64  \n",
      " 6    year         261 non-null    int64  \n",
      " 7    brand        261 non-null    object \n",
      "dtypes: float64(3), int64(4), object(1)\n",
      "memory usage: 16.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining Our Problem\n",
    "\n",
    "Let's see if we can predict whether a car is American or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " US.        162\n",
       " Japan.      51\n",
       " Europe.     48\n",
       "Name:  brand, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[' brand'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['target'] = df[' brand'] == ' US.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mpg</th>\n",
       "      <th>cylinders</th>\n",
       "      <th>cubicinches</th>\n",
       "      <th>hp</th>\n",
       "      <th>weightlbs</th>\n",
       "      <th>time-to-60</th>\n",
       "      <th>year</th>\n",
       "      <th>brand</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.0</td>\n",
       "      <td>8</td>\n",
       "      <td>350.0</td>\n",
       "      <td>165</td>\n",
       "      <td>4209.0</td>\n",
       "      <td>12</td>\n",
       "      <td>1972</td>\n",
       "      <td>US.</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31.9</td>\n",
       "      <td>4</td>\n",
       "      <td>89.0</td>\n",
       "      <td>71</td>\n",
       "      <td>1925.0</td>\n",
       "      <td>14</td>\n",
       "      <td>1980</td>\n",
       "      <td>Europe.</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17.0</td>\n",
       "      <td>8</td>\n",
       "      <td>302.0</td>\n",
       "      <td>140</td>\n",
       "      <td>3449.0</td>\n",
       "      <td>11</td>\n",
       "      <td>1971</td>\n",
       "      <td>US.</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15.0</td>\n",
       "      <td>8</td>\n",
       "      <td>400.0</td>\n",
       "      <td>150</td>\n",
       "      <td>3761.0</td>\n",
       "      <td>10</td>\n",
       "      <td>1971</td>\n",
       "      <td>US.</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30.5</td>\n",
       "      <td>4</td>\n",
       "      <td>98.0</td>\n",
       "      <td>63</td>\n",
       "      <td>2051.0</td>\n",
       "      <td>17</td>\n",
       "      <td>1978</td>\n",
       "      <td>US.</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mpg   cylinders   cubicinches   hp   weightlbs   time-to-60   year  \\\n",
       "0  14.0           8         350.0  165      4209.0           12   1972   \n",
       "1  31.9           4          89.0   71      1925.0           14   1980   \n",
       "2  17.0           8         302.0  140      3449.0           11   1971   \n",
       "3  15.0           8         400.0  150      3761.0           10   1971   \n",
       "4  30.5           4          98.0   63      2051.0           17   1978   \n",
       "\n",
       "      brand  target  \n",
       "0       US.    True  \n",
       "1   Europe.   False  \n",
       "2       US.    True  \n",
       "3       US.    True  \n",
       "4       US.    True  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fix Columns with Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X = df.drop(['target', ' brand'], axis=1)\n",
    "y = df['target']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "si = SimpleImputer()\n",
    "\n",
    "si.fit(X_train)\n",
    "\n",
    "X_tr_im = si.transform(X_train)\n",
    "X_te_im = si.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Version 1: Simple Averaging\n",
    "\n",
    "> Each model uses the same data to train and then we \"vote\" to make a prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Ensemble Techniques - How do we use the wisdom of the crowd? \n",
    "\n",
    "1. **Max Voting** - The max voting method is generally used for classification problems. In this technique, multiple models are used to make predictions for each data point. The predictions by each model are considered as a ‘vote’. The predictions which we get from the majority of the models are used as the final prediction.\n",
    "\n",
    "> For example, when you asked 5 of your colleagues to rate your movie (out of 5); we’ll assume three of them rated it as 4 while two of them gave it a 5. Since the majority gave a rating of 4, the final rating will be taken as 4. You can consider this as taking the mode of all the predictions.\n",
    "\n",
    "2. **Averaging** - Similar to the max voting technique, multiple predictions are made for each data point in averaging. In this method, we take an average of predictions from all the models and use it to make the final prediction. Averaging can be used for making predictions in regression problems or while calculating probabilities for classification problems.\n",
    "\n",
    "3. **Weighted Averaging** - This is an extension of the averaging method. All models are assigned different weights defining the importance of each model for prediction. For instance, if two of your colleagues are movie critics, while others have no prior experience in this field, then the answers by these two friends are given more importance as compared to the other people.\n",
    "\n",
    "[User Guide!](https://scikit-learn.org/stable/modules/ensemble.html)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Model 1 - Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=1000, random_state=42)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate and fit our logreg\n",
    "lr = LogisticRegression(max_iter=1000, random_state=42)\n",
    "\n",
    "lr.fit(X_tr_im, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median score: 0.8462 (+/- 0.0699)\n"
     ]
    }
   ],
   "source": [
    "# Check our scores\n",
    "scores = cross_val_score(estimator=lr, X=X_tr_im,\n",
    "                         y=y_train, cv=5)\n",
    "print(f\"Median score: {np.median(scores):.4f} (+/- {np.std(scores):.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8939393939393939"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test score\n",
    "lr.score(X_te_im, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Model 2 - KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=3)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate and fit a knn with k=3\n",
    "knn = KNeighborsClassifier(3)\n",
    "\n",
    "knn.fit(X_tr_im, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median score: 0.7692 (+/- 0.0205)\n"
     ]
    }
   ],
   "source": [
    "# Check our scores\n",
    "scores = cross_val_score(estimator=knn, X=X_tr_im,\n",
    "                y=y_train, cv=5)\n",
    "print(f\"Median score: {np.median(scores):.4f} (+/- {np.std(scores):.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7878787878787878"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test score\n",
    "knn.score(X_te_im, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Model 3 - Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(random_state=42)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate and fit an untuned decision tree\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "dt.fit(X_tr_im, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median score: 0.8718 (+/- 0.0417)\n"
     ]
    }
   ],
   "source": [
    "# Check our scores\n",
    "scores = cross_val_score(estimator=dt, X=X_tr_im,\n",
    "                         y=y_train, cv=5)\n",
    "print(f\"Median score: {np.median(scores):.4f} (+/- {np.std(scores):.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7878787878787878"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test score\n",
    "dt.score(X_te_im, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Averaging the Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Building a `VotingClassifier`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Of course there's an SKLearn class for that!\n",
    "\n",
    "[Documentation](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.VotingClassifier.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to import!\n",
    "from sklearn.ensemble import VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('logreg',\n",
       "                              LogisticRegression(max_iter=1000,\n",
       "                                                 random_state=42)),\n",
       "                             ('knn-3', KNeighborsClassifier(n_neighbors=3)),\n",
       "                             ('dt', DecisionTreeClassifier(random_state=42))])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate and fit our VotingClassifier\n",
    "avg = VotingClassifier([\n",
    "    ('logreg', lr),\n",
    "    ('knn-3', knn),\n",
    "    ('dt', dt)\n",
    "])\n",
    "\n",
    "avg.fit(X_tr_im, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median score: 0.8718 (+/- 0.0417)\n"
     ]
    }
   ],
   "source": [
    "# Check our scores\n",
    "scores = cross_val_score(estimator=avg, X=X_tr_im,\n",
    "                         y=y_train, cv=5)\n",
    "print(f\"Median score: {np.median(scores):.4f} (+/- {np.std(scores):.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8636363636363636"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test score\n",
    "avg.score(X_te_im, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Weighted Averaging with the `VotingClassifier`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "> Even if the vote is 50-50, you'd probably side with the \"smart\" ones more"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "This meta-estimator is not as good as one of our base estimators, so in this case the averaging did not work very well. Realizing that the logistic regression is performing better than the decision tree and the k-nearest-neighbors model, however, we might decide to build a meta-estimator by calculating a **weighted average** of the base estimators' predictions. And we can weight, or bias, this estimator in favor of the best-performing base estimator. Suppose we weight the logistic regression 50%, the knn model 25%, and the decision tree 25%:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('logreg',\n",
       "                              LogisticRegression(max_iter=1000,\n",
       "                                                 random_state=42)),\n",
       "                             ('knn-3', KNeighborsClassifier(n_neighbors=3)),\n",
       "                             ('dt', DecisionTreeClassifier(random_state=42))],\n",
       "                 weights=[0.5, 0.25, 0.25])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate and fit, this time with the weights outlined above\n",
    "w_avg = VotingClassifier([\n",
    "    ('logreg', lr),\n",
    "    ('knn-3', knn),\n",
    "    ('dt', dt)\n",
    "], weights=[.5,.25,.25])\n",
    "\n",
    "w_avg.fit(X_tr_im, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median score: 0.8718 (+/- 0.0576)\n"
     ]
    }
   ],
   "source": [
    "# Check our scores\n",
    "scores = cross_val_score(estimator=w_avg, X=X_tr_im,\n",
    "                         y=y_train, cv=5)\n",
    "print(f\"Median score: {np.median(scores):.4f} (+/- {np.std(scores):.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9242424242424242"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test score\n",
    "w_avg.score(X_te_im, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Version 2: Bagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "A single decision tree will often overfit your training data. Let's see if we have evidence of that in the current case:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scoring our earlier dt on train\n",
    "dt.score(X_tr_im, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### 🧠 Knowledge Check: What is this score? And why is it equal to 1?\n",
    "\n",
    "- accuracy. it's equal to 1 on training data because it's super oveerfit.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median score: 0.8718 (+/- 0.0417)\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(estimator=dt, X=X_tr_im,\n",
    "                         y=y_train, cv=5)\n",
    "print(f\"Median score: {np.median(scores):.4f} (+/- {np.std(scores):.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7878787878787878"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt.score(X_te_im, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "But it's often better to do something else: Plant another tree!\n",
    "\n",
    "Of course, if a second tree is going to be of any value, it has to be *different* from the first. Here's a good algorithm for achieving that:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bootstrap Aggregation\n",
    "\n",
    "The idea behind **bagging** is combining the results of multiple models (for instance, all decision trees) to get a generalized result. Here’s a question: If you create all the models on the same set of data and combine it, will it be useful? There is a high chance that these models will give the same result since they are getting the same input. So how can we solve this problem? One of the techniques is bootstrapping.\n",
    "\n",
    "**Bootstrapping** is a sampling technique in which we create subsets of observations from the original dataset, with replacement. The size of the subsets is the same as the size of the original set.\n",
    "\n",
    "**Bagging (or Bootstrap Aggregating)** technique uses these subsets (bags) to get a fair idea of the distribution (complete set). The size of subsets created for bagging may be less than the original set.\n",
    "![](https://cdn.analyticsvidhya.com/wp-content/uploads/2018/05/image20-768x289.png)\n",
    "\n",
    "\n",
    "Multiple subsets are created from the original dataset, selecting observations with replacement.\n",
    "A base model (weak model) is created on each of these subsets.\n",
    "The models run in parallel and are independent of each other.\n",
    "The final predictions are determined by combining the predictions from all the models.\n",
    "![](https://cdn.analyticsvidhya.com/wp-content/uploads/2018/05/Screenshot-from-2018-05-08-13-11-49-768x580.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Bagging with `sklearn`\n",
    "\n",
    "[Documentation](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.BaggingClassifier.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import!\n",
    "from sklearn.ensemble import BaggingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaggingClassifier(max_samples=0.75, n_estimators=100, random_state=42)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instatiate and fit a BaggingClassifier with n_estimators=100\n",
    "# Note the base esimator is by default a decision tree\n",
    "bag = BaggingClassifier(n_estimators=100, max_samples=.75, random_state=42)\n",
    "\n",
    "bag.fit(X_tr_im, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median score: 0.8718 (+/- 0.0363)\n"
     ]
    }
   ],
   "source": [
    "# Check our scores\n",
    "scores = cross_val_score(estimator=bag, X=X_tr_im,\n",
    "                         y=y_train, cv=5)\n",
    "print(f\"Median score: {np.median(scores):.4f} (+/- {np.std(scores):.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8939393939393939"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test score\n",
    "bag.score(X_te_im, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Fitting a Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Let's add an extra layer of randomization: Instead of using *all* the features of my model to optimize a branch at each node, I'll just choose a subset of my features.\n",
    "\n",
    "That's the essence of a random forest model. Note that there are now **two** levels of random sampling happening: To build a new tree, I'll be taking only some of my data points; and at any branching point in a tree, I'll be using only some of my features to determine the split."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Steps:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "1. Save a portion of data for validation (**out-of-bag**), the rest for training (**bag**)\n",
    "2. The data for training (**bag**) is then split up by randomly selecting predictors\n",
    "3. Grow/train your tree with the training data using just those features\n",
    "4. Use our validation set (**out-of-bag**), take out the columns used in our tree from the previous step, and predict using the tree & this *out-of-bag* data\n",
    "5. Compare on how well the tree did *out-of-bag error*\n",
    "6. Repeat to make new trees and use the result to \"vote\" for the final decision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest with `sklearn`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "[Documentation](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import!\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=5, random_state=93)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate and fit a RandomForestClassifier\n",
    "\n",
    "rfc = RandomForestClassifier(random_state=93, max_depth=5)\n",
    "\n",
    "rfc.fit(X_tr_im, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median score: 0.8718 (+/- 0.0417)\n"
     ]
    }
   ],
   "source": [
    "# Check our scores\n",
    "scores = cross_val_score(estimator=rfc, X=X_tr_im,\n",
    "                         y=y_train, cv=5)\n",
    "print(f\"Median score: {np.median(scores):.4f} (+/- {np.std(scores):.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Test score\n",
    "score = rfc.score(X_te_im, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Cool Features of Random Forests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Investigate Your Forest 🌲🌲👀🌲🌲"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We can check out our trained estimators after training the ensemble. This isn't necessarily unique to random forests, but since the base model is always a decision tree we can really investigate how the model is working!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[DecisionTreeClassifier(max_depth=5, max_features='auto', random_state=456788389),\n",
       " DecisionTreeClassifier(max_depth=5, max_features='auto', random_state=340604251),\n",
       " DecisionTreeClassifier(max_depth=5, max_features='auto', random_state=676507012),\n",
       " DecisionTreeClassifier(max_depth=5, max_features='auto',\n",
       "                        random_state=1604596888),\n",
       " DecisionTreeClassifier(max_depth=5, max_features='auto',\n",
       "                        random_state=1319590095),\n",
       " DecisionTreeClassifier(max_depth=5, max_features='auto', random_state=955719265),\n",
       " DecisionTreeClassifier(max_depth=5, max_features='auto',\n",
       "                        random_state=1984289877),\n",
       " DecisionTreeClassifier(max_depth=5, max_features='auto', random_state=451090992),\n",
       " DecisionTreeClassifier(max_depth=5, max_features='auto', random_state=154270541),\n",
       " DecisionTreeClassifier(max_depth=5, max_features='auto', random_state=576594157),\n",
       " DecisionTreeClassifier(max_depth=5, max_features='auto', random_state=685625780),\n",
       " DecisionTreeClassifier(max_depth=5, max_features='auto', random_state=89278132),\n",
       " DecisionTreeClassifier(max_depth=5, max_features='auto',\n",
       "                        random_state=2144805881),\n",
       " DecisionTreeClassifier(max_depth=5, max_features='auto', random_state=494720179),\n",
       " DecisionTreeClassifier(max_depth=5, max_features='auto',\n",
       "                        random_state=1077967765),\n",
       " DecisionTreeClassifier(max_depth=5, max_features='auto',\n",
       "                        random_state=1878432817),\n",
       " DecisionTreeClassifier(max_depth=5, max_features='auto', random_state=165451594),\n",
       " DecisionTreeClassifier(max_depth=5, max_features='auto', random_state=661722017),\n",
       " DecisionTreeClassifier(max_depth=5, max_features='auto',\n",
       "                        random_state=1054437896),\n",
       " DecisionTreeClassifier(max_depth=5, max_features='auto', random_state=774115911),\n",
       " DecisionTreeClassifier(max_depth=5, max_features='auto',\n",
       "                        random_state=1011886544),\n",
       " DecisionTreeClassifier(max_depth=5, max_features='auto',\n",
       "                        random_state=1766325464),\n",
       " DecisionTreeClassifier(max_depth=5, max_features='auto',\n",
       "                        random_state=1788211721),\n",
       " DecisionTreeClassifier(max_depth=5, max_features='auto',\n",
       "                        random_state=1656139575),\n",
       " DecisionTreeClassifier(max_depth=5, max_features='auto',\n",
       "                        random_state=1481848574),\n",
       " DecisionTreeClassifier(max_depth=5, max_features='auto',\n",
       "                        random_state=1601457547),\n",
       " DecisionTreeClassifier(max_depth=5, max_features='auto',\n",
       "                        random_state=1742239493),\n",
       " DecisionTreeClassifier(max_depth=5, max_features='auto', random_state=15878572),\n",
       " DecisionTreeClassifier(max_depth=5, max_features='auto',\n",
       "                        random_state=2038213419),\n",
       " DecisionTreeClassifier(max_depth=5, max_features='auto', random_state=725923071),\n",
       " DecisionTreeClassifier(max_depth=5, max_features='auto', random_state=829698281),\n",
       " DecisionTreeClassifier(max_depth=5, max_features='auto', random_state=625549169),\n",
       " DecisionTreeClassifier(max_depth=5, max_features='auto', random_state=795270642),\n",
       " DecisionTreeClassifier(max_depth=5, max_features='auto', random_state=316410158),\n",
       " DecisionTreeClassifier(max_depth=5, max_features='auto', random_state=293238287),\n",
       " DecisionTreeClassifier(max_depth=5, max_features='auto', random_state=690324640),\n",
       " DecisionTreeClassifier(max_depth=5, max_features='auto', random_state=525240177),\n",
       " DecisionTreeClassifier(max_depth=5, max_features='auto', random_state=454750811),\n",
       " DecisionTreeClassifier(max_depth=5, max_features='auto', random_state=433870597),\n",
       " DecisionTreeClassifier(max_depth=5, max_features='auto', random_state=251921958),\n",
       " DecisionTreeClassifier(max_depth=5, max_features='auto',\n",
       "                        random_state=1586752531),\n",
       " DecisionTreeClassifier(max_depth=5, max_features='auto', random_state=89358156),\n",
       " DecisionTreeClassifier(max_depth=5, max_features='auto', random_state=226111887),\n",
       " DecisionTreeClassifier(max_depth=5, max_features='auto',\n",
       "                        random_state=1448640370),\n",
       " DecisionTreeClassifier(max_depth=5, max_features='auto', random_state=296630001),\n",
       " DecisionTreeClassifier(max_depth=5, max_features='auto',\n",
       "                        random_state=1359519035),\n",
       " DecisionTreeClassifier(max_depth=5, max_features='auto',\n",
       "                        random_state=1740900015),\n",
       " DecisionTreeClassifier(max_depth=5, max_features='auto', random_state=11365415),\n",
       " DecisionTreeClassifier(max_depth=5, max_features='auto',\n",
       "                        random_state=1299285921),\n",
       " DecisionTreeClassifier(max_depth=5, max_features='auto', random_state=212573483),\n",
       " DecisionTreeClassifier(max_depth=5, max_features='auto',\n",
       "                        random_state=1225663647),\n",
       " DecisionTreeClassifier(max_depth=5, max_features='auto', random_state=744914717),\n",
       " DecisionTreeClassifier(max_depth=5, max_features='auto',\n",
       "                        random_state=1197062289),\n",
       " DecisionTreeClassifier(max_depth=5, max_features='auto', random_state=608345124),\n",
       " DecisionTreeClassifier(max_depth=5, max_features='auto', random_state=397436053),\n",
       " DecisionTreeClassifier(max_depth=5, max_features='auto',\n",
       "                        random_state=1572372712),\n",
       " DecisionTreeClassifier(max_depth=5, max_features='auto',\n",
       "                        random_state=1972160369),\n",
       " DecisionTreeClassifier(max_depth=5, max_features='auto',\n",
       "                        random_state=2084827809),\n",
       " DecisionTreeClassifier(max_depth=5, max_features='auto',\n",
       "                        random_state=1477307256),\n",
       " DecisionTreeClassifier(max_depth=5, max_features='auto', random_state=893886039),\n",
       " DecisionTreeClassifier(max_depth=5, max_features='auto',\n",
       "                        random_state=1166836082),\n",
       " DecisionTreeClassifier(max_depth=5, max_features='auto', random_state=496637242),\n",
       " DecisionTreeClassifier(max_depth=5, max_features='auto',\n",
       "                        random_state=2050869269),\n",
       " DecisionTreeClassifier(max_depth=5, max_features='auto', random_state=328481628),\n",
       " DecisionTreeClassifier(max_depth=5, max_features='auto',\n",
       "                        random_state=2051059103),\n",
       " DecisionTreeClassifier(max_depth=5, max_features='auto',\n",
       "                        random_state=1634023096),\n",
       " DecisionTreeClassifier(max_depth=5, max_features='auto', random_state=665140610),\n",
       " DecisionTreeClassifier(max_depth=5, max_features='auto', random_state=747980307),\n",
       " DecisionTreeClassifier(max_depth=5, max_features='auto', random_state=863505934),\n",
       " DecisionTreeClassifier(max_depth=5, max_features='auto',\n",
       "                        random_state=2013430934),\n",
       " DecisionTreeClassifier(max_depth=5, max_features='auto',\n",
       "                        random_state=1611398116),\n",
       " DecisionTreeClassifier(max_depth=5, max_features='auto', random_state=619482827),\n",
       " DecisionTreeClassifier(max_depth=5, max_features='auto',\n",
       "                        random_state=1196615607),\n",
       " DecisionTreeClassifier(max_depth=5, max_features='auto', random_state=945877417),\n",
       " DecisionTreeClassifier(max_depth=5, max_features='auto',\n",
       "                        random_state=1394899267),\n",
       " DecisionTreeClassifier(max_depth=5, max_features='auto',\n",
       "                        random_state=1340187224),\n",
       " DecisionTreeClassifier(max_depth=5, max_features='auto', random_state=253517405),\n",
       " DecisionTreeClassifier(max_depth=5, max_features='auto', random_state=629386975),\n",
       " DecisionTreeClassifier(max_depth=5, max_features='auto',\n",
       "                        random_state=1547925669),\n",
       " DecisionTreeClassifier(max_depth=5, max_features='auto',\n",
       "                        random_state=1742530210),\n",
       " DecisionTreeClassifier(max_depth=5, max_features='auto',\n",
       "                        random_state=1923915591),\n",
       " DecisionTreeClassifier(max_depth=5, max_features='auto',\n",
       "                        random_state=1727881865),\n",
       " DecisionTreeClassifier(max_depth=5, max_features='auto',\n",
       "                        random_state=1953142816),\n",
       " DecisionTreeClassifier(max_depth=5, max_features='auto', random_state=16191692),\n",
       " DecisionTreeClassifier(max_depth=5, max_features='auto',\n",
       "                        random_state=2000215677),\n",
       " DecisionTreeClassifier(max_depth=5, max_features='auto', random_state=611782762),\n",
       " DecisionTreeClassifier(max_depth=5, max_features='auto',\n",
       "                        random_state=1834394679),\n",
       " DecisionTreeClassifier(max_depth=5, max_features='auto',\n",
       "                        random_state=1828260434),\n",
       " DecisionTreeClassifier(max_depth=5, max_features='auto', random_state=547834669),\n",
       " DecisionTreeClassifier(max_depth=5, max_features='auto', random_state=542117935),\n",
       " DecisionTreeClassifier(max_depth=5, max_features='auto', random_state=757902147),\n",
       " DecisionTreeClassifier(max_depth=5, max_features='auto',\n",
       "                        random_state=1790009613),\n",
       " DecisionTreeClassifier(max_depth=5, max_features='auto',\n",
       "                        random_state=2009119077),\n",
       " DecisionTreeClassifier(max_depth=5, max_features='auto', random_state=500795935),\n",
       " DecisionTreeClassifier(max_depth=5, max_features='auto',\n",
       "                        random_state=1918061611),\n",
       " DecisionTreeClassifier(max_depth=5, max_features='auto',\n",
       "                        random_state=1423826995),\n",
       " DecisionTreeClassifier(max_depth=5, max_features='auto', random_state=338485344),\n",
       " DecisionTreeClassifier(max_depth=5, max_features='auto',\n",
       "                        random_state=1507766687),\n",
       " DecisionTreeClassifier(max_depth=5, max_features='auto', random_state=6324909),\n",
       " DecisionTreeClassifier(max_depth=5, max_features='auto',\n",
       "                        random_state=1410910058)]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_estimators = rfc.estimators_ \n",
    "print(len(model_estimators))\n",
    "model_estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall model's score was 0.909\n",
      "======================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(max_depth=5, max_features='auto',\n",
       "                       random_state=1423826995)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tModel gave score of 0.864\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(max_depth=5, max_features='auto', random_state=338485344)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tModel gave score of 0.848\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(max_depth=5, max_features='auto',\n",
       "                       random_state=1507766687)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tModel gave score of 0.742\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(max_depth=5, max_features='auto', random_state=6324909)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tModel gave score of 0.712\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(max_depth=5, max_features='auto',\n",
       "                       random_state=1410910058)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tModel gave score of 0.773\n"
     ]
    }
   ],
   "source": [
    "print(f'Overall model\\'s score was {score:.3f}')\n",
    "print('='*70)\n",
    "\n",
    "for model in model_estimators[-5:]:\n",
    "    display(model)\n",
    "    model_score = model.score(X_te_im, y_test)\n",
    "    print(f'\\tModel gave score of {model_score:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Feature Importances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We can use [`.feature_importances_`](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html#sklearn.ensemble.RandomForestClassifier.feature_importances_) property of the trained model to get an idea of what features mattered the most"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mpg': 0.1120439179122671,\n",
       " ' cylinders': 0.14315108505112964,\n",
       " ' cubicinches': 0.34518720493721144,\n",
       " ' hp': 0.11204619696880583,\n",
       " ' weightlbs': 0.17174211863242275,\n",
       " ' time-to-60': 0.0477848864323002,\n",
       " ' year': 0.06804459006586315}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_import = {name: imp for name, imp in zip(X_train.columns, rfc.feature_importances_)}\n",
    "feat_import"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Extremely Randomized Trees (Extra Trees)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Sometimes we might want even one more bit of randomization. Instead of always choosing the *optimal* branching path, we might just choose a branching path at random. If we're doing that, then we've got extremely randomized trees.\n",
    "\n",
    "There are now **three** levels of randomization: sampling of data, sampling of features, and random selection of branching paths.\n",
    "\n",
    "[Documentation](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.ExtraTreesClassifier.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import!\n",
    "from sklearn.ensemble import ExtraTreesClassifier, StackingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ExtraTreesClassifier(max_depth=5, random_state=42)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate and fit an ExtraTreesClassifier\n",
    "etc = ExtraTreesClassifier(random_state=42, max_depth=5)\n",
    "etc.fit(X_tr_im, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median score: 0.8718 (+/- 0.0429)\n"
     ]
    }
   ],
   "source": [
    "# Check our scores\n",
    "scores = cross_val_score(estimator=etc, X=X_tr_im,\n",
    "                         y=y_train, cv=5)\n",
    "print(f\"Median score: {np.median(scores):.4f} (+/- {np.std(scores):.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9090909090909091"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test score\n",
    "etc.score(X_te_im, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pros and Cons of Random Forests \n",
    "\n",
    "(FYI - Random Forests are the most common of the techniques we've explored today, hence the focus here! Many of these pros/cons would also apply to other ensemble or bagging techniques)\n",
    "\n",
    "**Pros:**\n",
    "* Strong performance -- because this is an ensemble algorithm, the model is naturally resistant to noise and variance in the data, and generally tends to perform quite well.\n",
    "\n",
    "* Interpretability: each tree in the random forest is a Glass-Box Model (meaning that the model is interpretable, allowing us to see how it arrived at a certain decision)\n",
    "\n",
    "**Cons:**\n",
    "* Computational complexity: On large datasets, the runtime can be quite slow compared to other algorithms.\n",
    "\n",
    "* Memory usage: Random forests tend to have a larger memory footprint that other models. It's not uncommon to see random forests that were trained on large datasets have memory footprints in the tens, or even hundreds of MB.\n",
    "\n",
    "* Interpretability: although each tree is a Glass-Box Model and quite interpretable, it can be harder to grasp exactly what's happening in aggregat without some extra work (and the `feature_importances_` given by random forest models are notoriously bad/unreliable!)\n",
    "\n",
    "    - Additional details about why we don't trust random forest feature importances: https://explained.ai/rf-importance/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Level Up: Stacking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Meta-Classifier/Meta-Regressor\n",
    "\n",
    "- First, we ask several different models to make predictions about the target\n",
    "- Rather than taking a simple average or vote to determine the outcome, feed these results into a final model that makes the prediction based on the other models’ predictions\n",
    "- If it seems like we are approaching a neural network...you are correct!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Remember weighted averaging? Stacking is about using DS models to estimate those weights for us. This means we'll have one layer of base estimators and another layer that is \"**trained to optimally combine the model predictions to form a new set of predictions**\". See [this short blog post](https://blogs.sas.com/content/subconsciousmusings/2017/05/18/stacked-ensemble-models-win-data-science-competitions/) for more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Initial Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import xlrd\n",
    "import os\n",
    "\n",
    "wb = xlrd.open_workbook('data/Sales Report.xls',\n",
    "                        logfile=open(os.devnull, 'w'))\n",
    "\n",
    "sales = pd.read_excel(wb)\n",
    "sales = sales.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Row ID</th>\n",
       "      <th>Order ID</th>\n",
       "      <th>Order Date</th>\n",
       "      <th>Ship Date</th>\n",
       "      <th>Ship Mode</th>\n",
       "      <th>Customer ID</th>\n",
       "      <th>Customer Name</th>\n",
       "      <th>Segment</th>\n",
       "      <th>Country</th>\n",
       "      <th>City</th>\n",
       "      <th>...</th>\n",
       "      <th>Postal Code</th>\n",
       "      <th>Region</th>\n",
       "      <th>Product ID</th>\n",
       "      <th>Category</th>\n",
       "      <th>Sub-Category</th>\n",
       "      <th>Product Name</th>\n",
       "      <th>Sales</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Profit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>CA-2017-152156</td>\n",
       "      <td>2017-11-08</td>\n",
       "      <td>2017-11-11</td>\n",
       "      <td>Second Class</td>\n",
       "      <td>CG-12520</td>\n",
       "      <td>Claire Gute</td>\n",
       "      <td>Consumer</td>\n",
       "      <td>United States</td>\n",
       "      <td>Henderson</td>\n",
       "      <td>...</td>\n",
       "      <td>42420.0</td>\n",
       "      <td>South</td>\n",
       "      <td>FUR-BO-10001798</td>\n",
       "      <td>Furniture</td>\n",
       "      <td>Bookcases</td>\n",
       "      <td>Bush Somerset Collection Bookcase</td>\n",
       "      <td>261.9600</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>41.9136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>CA-2017-152156</td>\n",
       "      <td>2017-11-08</td>\n",
       "      <td>2017-11-11</td>\n",
       "      <td>Second Class</td>\n",
       "      <td>CG-12520</td>\n",
       "      <td>Claire Gute</td>\n",
       "      <td>Consumer</td>\n",
       "      <td>United States</td>\n",
       "      <td>Henderson</td>\n",
       "      <td>...</td>\n",
       "      <td>42420.0</td>\n",
       "      <td>South</td>\n",
       "      <td>FUR-CH-10000454</td>\n",
       "      <td>Furniture</td>\n",
       "      <td>Chairs</td>\n",
       "      <td>Hon Deluxe Fabric Upholstered Stacking Chairs,...</td>\n",
       "      <td>731.9400</td>\n",
       "      <td>3</td>\n",
       "      <td>0.00</td>\n",
       "      <td>219.5820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>CA-2017-138688</td>\n",
       "      <td>2017-06-12</td>\n",
       "      <td>2017-06-16</td>\n",
       "      <td>Second Class</td>\n",
       "      <td>DV-13045</td>\n",
       "      <td>Darrin Van Huff</td>\n",
       "      <td>Corporate</td>\n",
       "      <td>United States</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>...</td>\n",
       "      <td>90036.0</td>\n",
       "      <td>West</td>\n",
       "      <td>OFF-LA-10000240</td>\n",
       "      <td>Office Supplies</td>\n",
       "      <td>Labels</td>\n",
       "      <td>Self-Adhesive Address Labels for Typewriters b...</td>\n",
       "      <td>14.6200</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6.8714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>US-2016-108966</td>\n",
       "      <td>2016-10-11</td>\n",
       "      <td>2016-10-18</td>\n",
       "      <td>Standard Class</td>\n",
       "      <td>SO-20335</td>\n",
       "      <td>Sean O'Donnell</td>\n",
       "      <td>Consumer</td>\n",
       "      <td>United States</td>\n",
       "      <td>Fort Lauderdale</td>\n",
       "      <td>...</td>\n",
       "      <td>33311.0</td>\n",
       "      <td>South</td>\n",
       "      <td>FUR-TA-10000577</td>\n",
       "      <td>Furniture</td>\n",
       "      <td>Tables</td>\n",
       "      <td>Bretford CR4500 Series Slim Rectangular Table</td>\n",
       "      <td>957.5775</td>\n",
       "      <td>5</td>\n",
       "      <td>0.45</td>\n",
       "      <td>-383.0310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>US-2016-108966</td>\n",
       "      <td>2016-10-11</td>\n",
       "      <td>2016-10-18</td>\n",
       "      <td>Standard Class</td>\n",
       "      <td>SO-20335</td>\n",
       "      <td>Sean O'Donnell</td>\n",
       "      <td>Consumer</td>\n",
       "      <td>United States</td>\n",
       "      <td>Fort Lauderdale</td>\n",
       "      <td>...</td>\n",
       "      <td>33311.0</td>\n",
       "      <td>South</td>\n",
       "      <td>OFF-ST-10000760</td>\n",
       "      <td>Office Supplies</td>\n",
       "      <td>Storage</td>\n",
       "      <td>Eldon Fold 'N Roll Cart System</td>\n",
       "      <td>22.3680</td>\n",
       "      <td>2</td>\n",
       "      <td>0.20</td>\n",
       "      <td>2.5164</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Row ID        Order ID Order Date  Ship Date       Ship Mode Customer ID  \\\n",
       "0       1  CA-2017-152156 2017-11-08 2017-11-11    Second Class    CG-12520   \n",
       "1       2  CA-2017-152156 2017-11-08 2017-11-11    Second Class    CG-12520   \n",
       "2       3  CA-2017-138688 2017-06-12 2017-06-16    Second Class    DV-13045   \n",
       "3       4  US-2016-108966 2016-10-11 2016-10-18  Standard Class    SO-20335   \n",
       "4       5  US-2016-108966 2016-10-11 2016-10-18  Standard Class    SO-20335   \n",
       "\n",
       "     Customer Name    Segment        Country             City  ...  \\\n",
       "0      Claire Gute   Consumer  United States        Henderson  ...   \n",
       "1      Claire Gute   Consumer  United States        Henderson  ...   \n",
       "2  Darrin Van Huff  Corporate  United States      Los Angeles  ...   \n",
       "3   Sean O'Donnell   Consumer  United States  Fort Lauderdale  ...   \n",
       "4   Sean O'Donnell   Consumer  United States  Fort Lauderdale  ...   \n",
       "\n",
       "  Postal Code  Region       Product ID         Category Sub-Category  \\\n",
       "0     42420.0   South  FUR-BO-10001798        Furniture    Bookcases   \n",
       "1     42420.0   South  FUR-CH-10000454        Furniture       Chairs   \n",
       "2     90036.0    West  OFF-LA-10000240  Office Supplies       Labels   \n",
       "3     33311.0   South  FUR-TA-10000577        Furniture       Tables   \n",
       "4     33311.0   South  OFF-ST-10000760  Office Supplies      Storage   \n",
       "\n",
       "                                        Product Name     Sales  Quantity  \\\n",
       "0                  Bush Somerset Collection Bookcase  261.9600         2   \n",
       "1  Hon Deluxe Fabric Upholstered Stacking Chairs,...  731.9400         3   \n",
       "2  Self-Adhesive Address Labels for Typewriters b...   14.6200         2   \n",
       "3      Bretford CR4500 Series Slim Rectangular Table  957.5775         5   \n",
       "4                     Eldon Fold 'N Roll Cart System   22.3680         2   \n",
       "\n",
       "   Discount    Profit  \n",
       "0      0.00   41.9136  \n",
       "1      0.00  219.5820  \n",
       "2      0.00    6.8714  \n",
       "3      0.45 -383.0310  \n",
       "4      0.20    2.5164  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row ID                    int64\n",
       "Order ID                 object\n",
       "Order Date       datetime64[ns]\n",
       "Ship Date        datetime64[ns]\n",
       "Ship Mode                object\n",
       "Customer ID              object\n",
       "Customer Name            object\n",
       "Segment                  object\n",
       "Country                  object\n",
       "City                     object\n",
       "State                    object\n",
       "Postal Code             float64\n",
       "Region                   object\n",
       "Product ID               object\n",
       "Category                 object\n",
       "Sub-Category             object\n",
       "Product Name             object\n",
       "Sales                   float64\n",
       "Quantity                  int64\n",
       "Discount                float64\n",
       "Profit                  float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Office Supplies    6020\n",
       "Furniture          2119\n",
       "Technology         1844\n",
       "Name: Category, dtype: int64"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales['Category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Binders        1523\n",
       "Paper          1368\n",
       "Furnishings     957\n",
       "Phones          888\n",
       "Storage         845\n",
       "Art             795\n",
       "Accessories     773\n",
       "Chairs          616\n",
       "Appliances      465\n",
       "Labels          364\n",
       "Tables          319\n",
       "Envelopes       253\n",
       "Bookcases       227\n",
       "Fasteners       217\n",
       "Supplies        190\n",
       "Machines        115\n",
       "Copiers          68\n",
       "Name: Sub-Category, dtype: int64"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales['Sub-Category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X_num = sales[['Discount', 'Profit']].columns\n",
    "X_cat = sales[['Category', 'Sub-Category']].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X = sales[['Discount', 'Profit', 'Category', 'Sub-Category']]\n",
    "y = sales['Sales']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Setting Up a Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "numTrans = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "catTrans = Pipeline(steps=[\n",
    "    ('ohe', OneHotEncoder(drop='first',\n",
    "                          sparse=False))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pp = ColumnTransformer(transformers=[\n",
    "    ('num', numTrans, X_num),\n",
    "    ('cat', catTrans, X_cat)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ColumnTransformer(transformers=[('num',\n",
       "                                 Pipeline(steps=[('scaler', StandardScaler())]),\n",
       "                                 Index(['Discount', 'Profit'], dtype='object')),\n",
       "                                ('cat',\n",
       "                                 Pipeline(steps=[('ohe',\n",
       "                                                  OneHotEncoder(drop='first',\n",
       "                                                                sparse=False))]),\n",
       "                                 Index(['Category', 'Sub-Category'], dtype='object'))])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pp.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X_tr_pp = pp.transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Setting Up a Stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "estimators = [\n",
    "    ('lr', LinearRegression()),\n",
    "    ('knn', KNeighborsRegressor()),\n",
    "    ('rt', DecisionTreeRegressor())\n",
    "]\n",
    "\n",
    "sr = StackingRegressor(estimators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StackingRegressor(estimators=[('lr', LinearRegression()),\n",
       "                              ('knn', KNeighborsRegressor()),\n",
       "                              ('rt', DecisionTreeRegressor())])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sr.fit(X_tr_pp, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X_test_pp = pp.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score: 0.8532870281331015\n",
      "Test Score: 0.8146789011434006\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train Score: {sr.score(X_tr_pp, y_train)}\")\n",
    "print(f\"Test Score: {sr.score(X_test_pp, y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Comparison with Base Estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score: 0.36198304078636423\n",
      "Test Score: 0.42942244281549524\n"
     ]
    }
   ],
   "source": [
    "lr = LinearRegression().fit(X_tr_pp, y_train)\n",
    "print(f\"Train Score: {lr.score(X_tr_pp, y_train)}\")\n",
    "print(f\"Test Score: {lr.score(X_test_pp, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score: 0.8088770993187154\n",
      "Test Score: 0.7963215988357311\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsRegressor().fit(X_tr_pp, y_train)\n",
    "print(f\"Train Score: {knn.score(X_tr_pp, y_train)}\")\n",
    "print(f\"Test Score: {knn.score(X_test_pp, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score: 0.9955666197715463\n",
      "Test Score: 0.24555336439822484\n"
     ]
    }
   ],
   "source": [
    "rt = DecisionTreeRegressor().fit(X_tr_pp, y_train)\n",
    "print(f\"Train Score: {rt.score(X_tr_pp, y_train)}\")\n",
    "print(f\"Test Score: {rt.score(X_test_pp, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "TOC",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "288px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
