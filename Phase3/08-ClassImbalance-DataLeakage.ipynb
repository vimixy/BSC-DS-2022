{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Managing Unbalanced Targets and Preventing Data Leakage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "\n",
    "- avoid letting information about test sets get into the training of models\n",
    "- use best practices for building non-leaky workflows\n",
    "- repair leaky workflows\n",
    "- recognize imbalanced classification targets \n",
    "- describe sampling techniques that address unbalanced targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn\n",
    "\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.model_selection import train_test_split, cross_validate\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix, mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First: Avoiding Data Leakage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have encountered the idea of splitting our data into two, *training* our model on one bit and then *testing* it on the other. The goal is to have an unbiased assessment of our model, and so we want to make sure that nothing about our test data sneaks into the training run of the model, so our test is more like a true test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What's Wrong With This Picture?\n",
    "\n",
    "Look at the below code. We were sure to fit our model on our training data - does that mean we did everything right?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = load_diabetes(return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = StandardScaler().fit(X)\n",
    "X_scld = ss.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_scld, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  2.27107279 -11.5103763   25.30316447  18.14921047 -43.68812386\n",
      "  24.17505729   5.56228784  12.81809837  33.09612684   1.25207795] 151.66516982689885\n"
     ]
    }
   ],
   "source": [
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "print(lr.coef_, lr.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Discuss:\n",
    "\n",
    "- scaler fit before train/test split\n",
    "- so what?\n",
    "    - standard scaler fits 2 things: mean, standard deviation\n",
    "    - X and X_train will have different means and standard deviations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  46.5663043  -242.07901952  527.21060276  383.67247144 -928.07511491\n",
      "  515.36784384  115.57063455  273.44406458  701.76830324   26.2359726 ] 207.99298719235202\n"
     ]
    }
   ],
   "source": [
    "# If you found an error/mistake, let's fix it!\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X, y, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_tr_sc = scaler.transform(X_train2)\n",
    "X_te_sc = scaler.transform(X_test2)\n",
    "\n",
    "# Be sure to name your model something different\n",
    "lr2 = LinearRegression()\n",
    "lr2.fit(X_tr_sc, y_train2)\n",
    "\n",
    "# Then let's see if our coefficients are different:\n",
    "print(lr2.coef_, lr2.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error Comparison\n",
    "\n",
    "It's worth pointing out that, **for linear models**, there is **no** difference in modeling error:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our test RMSE for this model is 53.37.\n"
     ]
    }
   ],
   "source": [
    "y_test_hat = lr.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_test_hat, squared=False)\n",
    "print(f\"Our test RMSE for this model is {round(mse, 2)}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our test RMSE for this model is 53.37.\n"
     ]
    }
   ],
   "source": [
    "y_test2_hat = lr2.predict(X_te_sc)\n",
    "rmse = mean_squared_error(y_test2, y_test2_hat, squared=False)\n",
    "print(f\"Our test RMSE for this model is {round(mse, 2)}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will **NOT** be true for other sorts of models that use different loss functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general all preprocessing steps are subject to the same dangers here. Consider the preprocessing step of one-hot-encoding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "gun_poll = pd.read_csv('data/guns-polls.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>Start</th>\n",
       "      <th>End</th>\n",
       "      <th>Pollster</th>\n",
       "      <th>Population</th>\n",
       "      <th>Support</th>\n",
       "      <th>Republican Support</th>\n",
       "      <th>Democratic Support</th>\n",
       "      <th>URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>age-21</td>\n",
       "      <td>2/20/18</td>\n",
       "      <td>2/23/18</td>\n",
       "      <td>CNN/SSRS</td>\n",
       "      <td>Registered Voters</td>\n",
       "      <td>72</td>\n",
       "      <td>61</td>\n",
       "      <td>86</td>\n",
       "      <td>http://cdn.cnn.com/cnn/2018/images/02/25/rel3a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>age-21</td>\n",
       "      <td>2/27/18</td>\n",
       "      <td>2/28/18</td>\n",
       "      <td>NPR/Ipsos</td>\n",
       "      <td>Adults</td>\n",
       "      <td>82</td>\n",
       "      <td>72</td>\n",
       "      <td>92</td>\n",
       "      <td>https://www.ipsos.com/en-us/npripsos-poll-majo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>age-21</td>\n",
       "      <td>3/1/18</td>\n",
       "      <td>3/4/18</td>\n",
       "      <td>Rasmussen</td>\n",
       "      <td>Adults</td>\n",
       "      <td>67</td>\n",
       "      <td>59</td>\n",
       "      <td>76</td>\n",
       "      <td>http://www.rasmussenreports.com/public_content...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>age-21</td>\n",
       "      <td>2/22/18</td>\n",
       "      <td>2/26/18</td>\n",
       "      <td>Harris Interactive</td>\n",
       "      <td>Registered Voters</td>\n",
       "      <td>84</td>\n",
       "      <td>77</td>\n",
       "      <td>92</td>\n",
       "      <td>http://thehill.com/opinion/civil-rights/375993...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>age-21</td>\n",
       "      <td>3/3/18</td>\n",
       "      <td>3/5/18</td>\n",
       "      <td>Quinnipiac</td>\n",
       "      <td>Registered Voters</td>\n",
       "      <td>78</td>\n",
       "      <td>63</td>\n",
       "      <td>93</td>\n",
       "      <td>https://poll.qu.edu/national/release-detail?Re...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Question    Start      End            Pollster         Population  Support  \\\n",
       "0   age-21  2/20/18  2/23/18            CNN/SSRS  Registered Voters       72   \n",
       "1   age-21  2/27/18  2/28/18           NPR/Ipsos             Adults       82   \n",
       "2   age-21   3/1/18   3/4/18           Rasmussen             Adults       67   \n",
       "3   age-21  2/22/18  2/26/18  Harris Interactive  Registered Voters       84   \n",
       "4   age-21   3/3/18   3/5/18          Quinnipiac  Registered Voters       78   \n",
       "\n",
       "   Republican Support  Democratic Support  \\\n",
       "0                  61                  86   \n",
       "1                  72                  92   \n",
       "2                  59                  76   \n",
       "3                  77                  92   \n",
       "4                  63                  93   \n",
       "\n",
       "                                                 URL  \n",
       "0  http://cdn.cnn.com/cnn/2018/images/02/25/rel3a...  \n",
       "1  https://www.ipsos.com/en-us/npripsos-poll-majo...  \n",
       "2  http://www.rasmussenreports.com/public_content...  \n",
       "3  http://thehill.com/opinion/civil-rights/375993...  \n",
       "4  https://poll.qu.edu/national/release-detail?Re...  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gun_poll.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "YouGov                 12\n",
       "Morning Consult        11\n",
       "Quinnipiac              8\n",
       "NPR/Ipsos               7\n",
       "CNN/SSRS                5\n",
       "CBS News                4\n",
       "Suffolk                 2\n",
       "Rasmussen               2\n",
       "Marist                  1\n",
       "Harris Interactive      1\n",
       "YouGov/Huffpost         1\n",
       "SurveyMonkey            1\n",
       "Harvard/Harris          1\n",
       "ABC/Washington Post     1\n",
       "Name: Pollster, dtype: int64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gun_poll['Pollster'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now if I were to fit a one-hot encoder to the whole `Pollster` column here, the encoder would learn all the categories. But I need to prepare myself for the real-world possibility that unfamiliar categories may show up in future records. Let's explore this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First I'll do a split\n",
    "X_train, X_test = train_test_split(gun_poll, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit a `OneHotEncoder` to the `Pollster` column in my training data, then check to see which categories are represented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['x0_ABC/Washington Post', 'x0_CBS News', 'x0_CNN/SSRS',\n",
       "       'x0_Marist', 'x0_Morning Consult', 'x0_NPR/Ipsos', 'x0_Quinnipiac',\n",
       "       'x0_Rasmussen', 'x0_Suffolk', 'x0_YouGov', 'x0_YouGov/Huffpost'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate the one hot encoder, fit it just to the Pollster column\n",
    "ohe = OneHotEncoder()\n",
    "\n",
    "ohe.fit(X_train[['Pollster']])\n",
    "# Can see what categories it learned\n",
    "ohe.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found unknown categories ['SurveyMonkey', 'Harvard/Harris', 'Harris Interactive'] in column 0 during transform",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-52-69e7fbf52e1e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Transform our train and test sets\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mX_tr_ohs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mohe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Pollster'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mX_te_ohs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mohe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Pollster'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py\u001b[0m in \u001b[0;36mtransform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    426\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    427\u001b[0m         \u001b[1;31m# validation of X happens in _check_X called by _transform\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 428\u001b[1;33m         \u001b[0mX_int\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_mask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle_unknown\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle_unknown\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    429\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    430\u001b[0m         \u001b[0mn_samples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_int\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py\u001b[0m in \u001b[0;36m_transform\u001b[1;34m(self, X, handle_unknown)\u001b[0m\n\u001b[0;32m    122\u001b[0m                     msg = (\"Found unknown categories {0} in column {1}\"\n\u001b[0;32m    123\u001b[0m                            \" during transform\".format(diff, i))\n\u001b[1;32m--> 124\u001b[1;33m                     \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    125\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    126\u001b[0m                     \u001b[1;31m# Set the problematic rows to an acceptable value and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found unknown categories ['SurveyMonkey', 'Harvard/Harris', 'Harris Interactive'] in column 0 during transform"
     ]
    }
   ],
   "source": [
    "# Transform our train and test sets\n",
    "X_tr_ohs = ohe.transform(X_train[['Pollster']])\n",
    "X_te_ohs = ohe.transform(X_test[['Pollster']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the counts across those columns \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are categories in the testing data that don't appear in the training data! What should \n",
    "we do about that?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approaches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Strategy 1**: Divide up the categories proportionally when we do our train_test_split. If we're using `sklearn`'s tool, that means taking advantage of the `stratify` parameter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The least populated class in y has only 1 member, which is too few. The minimum number of groups for any class cannot be less than 2.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-54-de303dbf4df1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m new_X_train, new_X_test = train_test_split(gun_poll,\n\u001b[0m\u001b[0;32m      2\u001b[0m                                            \u001b[0mstratify\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgun_poll\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Pollster'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m                                            random_state=42)\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\model_selection\\_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[1;34m(*arrays, **options)\u001b[0m\n\u001b[0;32m   2150\u001b[0m                      random_state=random_state)\n\u001b[0;32m   2151\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2152\u001b[1;33m         \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstratify\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2153\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2154\u001b[0m     return list(chain.from_iterable((_safe_indexing(a, train),\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\model_selection\\_split.py\u001b[0m in \u001b[0;36msplit\u001b[1;34m(self, X, y, groups)\u001b[0m\n\u001b[0;32m   1339\u001b[0m         \"\"\"\n\u001b[0;32m   1340\u001b[0m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroups\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1341\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iter_indices\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1342\u001b[0m             \u001b[1;32myield\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1343\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\model_selection\\_split.py\u001b[0m in \u001b[0;36m_iter_indices\u001b[1;34m(self, X, y, groups)\u001b[0m\n\u001b[0;32m   1666\u001b[0m         \u001b[0mclass_counts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbincount\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_indices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1667\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclass_counts\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1668\u001b[1;33m             raise ValueError(\"The least populated class in y has only 1\"\n\u001b[0m\u001b[0;32m   1669\u001b[0m                              \u001b[1;34m\" member, which is too few. The minimum\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1670\u001b[0m                              \u001b[1;34m\" number of groups for any class cannot\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: The least populated class in y has only 1 member, which is too few. The minimum number of groups for any class cannot be less than 2."
     ]
    }
   ],
   "source": [
    "new_X_train, new_X_test = train_test_split(gun_poll,\n",
    "                                           stratify=gun_poll['Pollster'],\n",
    "                                           random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, in this case, we can't use this since some categories have only a single member."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Strategy 2**: Drop the categories with very few representatives.\n",
    "\n",
    "In the present case, let's try dropping the single-member categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "YouGov                 12\n",
       "Morning Consult        11\n",
       "Quinnipiac              8\n",
       "NPR/Ipsos               7\n",
       "CNN/SSRS                5\n",
       "CBS News                4\n",
       "Suffolk                 2\n",
       "Rasmussen               2\n",
       "Marist                  1\n",
       "Harris Interactive      1\n",
       "YouGov/Huffpost         1\n",
       "SurveyMonkey            1\n",
       "Harvard/Harris          1\n",
       "ABC/Washington Post     1\n",
       "Name: Pollster, dtype: int64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using value_counts, let's grab a list of all our 'bad categories' with only 1 instance\n",
    "poll_vals = gun_poll['Pollster'].value_counts()\n",
    "poll_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Marist', 'Harris Interactive', 'YouGov/Huffpost', 'SurveyMonkey',\n",
       "       'Harvard/Harris', 'ABC/Washington Post'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bad_cols = poll_vals.loc[poll_vals <= 1].index\n",
    "bad_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, use a lambda function in map to change values to \"Small Pollster\" if it's a bad category\n",
    "gun_poll['Pollster'] = gun_poll['Pollster'].map(lambda x: \"Small Pollster\" if x in bad_cols else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "YouGov             12\n",
       "Morning Consult    11\n",
       "Quinnipiac          8\n",
       "NPR/Ipsos           7\n",
       "Small Pollster      6\n",
       "CNN/SSRS            5\n",
       "CBS News            4\n",
       "Rasmussen           2\n",
       "Suffolk             2\n",
       "Name: Pollster, dtype: int64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Explore how that looks\n",
    "gun_poll['Pollster'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could now split this carefully so that new categories don't show up in the testing data. In fact, now we can try the stratified split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train3, X_test3 = train_test_split(gun_poll,\n",
    "                                     stratify=gun_poll['Pollster'],\n",
    "                                     test_size=0.3,\n",
    "                                     random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Morning Consult    8\n",
       "YouGov             8\n",
       "Quinnipiac         6\n",
       "NPR/Ipsos          5\n",
       "Small Pollster     4\n",
       "CBS News           3\n",
       "CNN/SSRS           3\n",
       "Rasmussen          1\n",
       "Suffolk            1\n",
       "Name: Pollster, dtype: int64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train3['Pollster'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "YouGov             4\n",
       "Morning Consult    3\n",
       "Small Pollster     2\n",
       "Quinnipiac         2\n",
       "NPR/Ipsos          2\n",
       "CNN/SSRS           2\n",
       "Rasmussen          1\n",
       "Suffolk            1\n",
       "CBS News           1\n",
       "Name: Pollster, dtype: int64"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test3['Pollster'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now every category that appears in the test data appears also in the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe = OneHotEncoder(drop=['Small Pollster'])\n",
    "\n",
    "ohe.fit(X_train3[['Pollster']])\n",
    "\n",
    "X_tr3_ohe = ohe.transform(X_train3[['Pollster']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['x0_CBS News', 'x0_CNN/SSRS', 'x0_Morning Consult', 'x0_NPR/Ipsos',\n",
       "       'x0_Quinnipiac', 'x0_Rasmussen', 'x0_Suffolk', 'x0_YouGov'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ohe.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Strategy 3**: Adjust the settings on the one-hot-encoder.\n",
    "\n",
    "For `sklearn`'s tool, we'll tweak the `handle_unknown` parameter:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leakage into Validation Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we employ cross-validation, then our training data points will be serving both for training and for validation. So there's a sense in which we can't help but let some information about our validation data sneak into the model.\n",
    "\n",
    "But strictly speaking, cross-validation means building *multiple* models, and we still want each to be blind to its validation set.\n",
    "\n",
    "The dangers of data leakage, therefore, are still very much real in the case of validation data. And they are often more subtle as well. Consider the following line of code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Going back to our diabetes data\n",
    "X, y = load_diabetes(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "ss = StandardScaler().fit(X_train)\n",
    "X_train_sc = ss.transform(X_train)\n",
    "X_test_sc = ss.transform(X_test)\n",
    "\n",
    "cv_results = cross_validate(estimator=LinearRegression(),\n",
    "                X=X_train_sc,\n",
    "                y=y_train,\n",
    "                return_estimator=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7680116279314527,\n",
       " -0.05303892863222729,\n",
       " 2.520206513666818,\n",
       " 3.7246885179366873,\n",
       " 4.554018949497577]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Looking at model coefficients on the first predictor\n",
    "[model.coef_[0] for model in cv_results['estimator']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've built five models here, and none of them saw any points from the test data, so we have no leaks, right?\n",
    "\n",
    "Wrong! We fit the `StandardScaler` to the whole training set, which means that information about *every* fold will affect every cross-validation. A better practice here would be to split our data into its cross-validation folds *first*. Then we can fit the scaler to only the training folds for each cross-validation.\n",
    "\n",
    "Of course, the more preprocessing steps we have, the more tedious it becomes to do this work! For such tasks it is often greatly beneficial to take advantage of `sklearn`'s `Pipeline`s, which we'll have more to say about later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The strategy to break up the data into cross validation folds would look like:\n",
    "\n",
    "- Split it into five validation folds using `KFold()`\n",
    "- For each split:\n",
    "\n",
    "- (i) fit a `StandardScaler` to the four-fold chunk and transform all five folds of data points with it\n",
    "- (ii) fit a `LinearRegression` to the four-fold chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.528989613900136\n",
      "0.39019139234952793\n",
      "0.4912994859993952\n",
      "0.6110332669605512\n",
      "0.2252452582281086\n"
     ]
    }
   ],
   "source": [
    "# Would look like:\n",
    "from sklearn.model_selection import KFold\n",
    "# KFold spits out index numbers, let's grab them to loop\n",
    "for train_ind, val_ind in KFold().split(X_train):\n",
    "    # Getting our train and val X\n",
    "    train = X_train[train_ind, :]\n",
    "    val = X_train[val_ind, :]\n",
    "    # Then our train and val y\n",
    "    target_train = y_train[train_ind]\n",
    "    target_val = y_train[val_ind]\n",
    "    \n",
    "    ss = StandardScaler().fit(train)\n",
    "    train_scld = ss.transform(train)\n",
    "    val_scld = ss.transform(val)\n",
    "    \n",
    "    lr = LinearRegression().fit(train_scld, target_train)\n",
    "    print(lr.score(val_scld, target_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Now: Handling Class Imbalances\n",
    "\n",
    "## Scenario: Identifying Fraudulent Credit Card Transactions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Credit card companies often try to identify whether a transaction is fraudulent at the time when it occurs, in order to decide whether to approve it. Let's build a classification model to try to classify fraudulent transactions! \n",
    "\n",
    "The data for this example came from [this Kaggle dataset](https://www.kaggle.com/mlg-ulb/creditcardfraud), but has been downsampled to just 10,000 rows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The dataset contains features for the transaction amount, the relative time of the transaction, and 28 other features formed using PCA. The target 'Class' is a 1 if the transaction was fraudulent, 0 otherwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/credit_fraud_small.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 31 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   Time    10000 non-null  float64\n",
      " 1   V1      10000 non-null  float64\n",
      " 2   V2      10000 non-null  float64\n",
      " 3   V3      10000 non-null  float64\n",
      " 4   V4      10000 non-null  float64\n",
      " 5   V5      10000 non-null  float64\n",
      " 6   V6      10000 non-null  float64\n",
      " 7   V7      10000 non-null  float64\n",
      " 8   V8      10000 non-null  float64\n",
      " 9   V9      10000 non-null  float64\n",
      " 10  V10     10000 non-null  float64\n",
      " 11  V11     10000 non-null  float64\n",
      " 12  V12     10000 non-null  float64\n",
      " 13  V13     10000 non-null  float64\n",
      " 14  V14     10000 non-null  float64\n",
      " 15  V15     10000 non-null  float64\n",
      " 16  V16     10000 non-null  float64\n",
      " 17  V17     10000 non-null  float64\n",
      " 18  V18     10000 non-null  float64\n",
      " 19  V19     10000 non-null  float64\n",
      " 20  V20     10000 non-null  float64\n",
      " 21  V21     10000 non-null  float64\n",
      " 22  V22     10000 non-null  float64\n",
      " 23  V23     10000 non-null  float64\n",
      " 24  V24     10000 non-null  float64\n",
      " 25  V25     10000 non-null  float64\n",
      " 26  V26     10000 non-null  float64\n",
      " 27  V27     10000 non-null  float64\n",
      " 28  V28     10000 non-null  float64\n",
      " 29  Amount  10000 non-null  float64\n",
      " 30  Class   10000 non-null  int64  \n",
      "dtypes: float64(30), int64(1)\n",
      "memory usage: 2.4 MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5966.033400</td>\n",
       "      <td>-0.241862</td>\n",
       "      <td>0.281949</td>\n",
       "      <td>0.906270</td>\n",
       "      <td>0.264148</td>\n",
       "      <td>-0.046398</td>\n",
       "      <td>0.133108</td>\n",
       "      <td>-0.071689</td>\n",
       "      <td>-0.064778</td>\n",
       "      <td>0.802224</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.051990</td>\n",
       "      <td>-0.152671</td>\n",
       "      <td>-0.033268</td>\n",
       "      <td>0.021335</td>\n",
       "      <td>0.087146</td>\n",
       "      <td>0.108140</td>\n",
       "      <td>0.005518</td>\n",
       "      <td>0.002915</td>\n",
       "      <td>63.030188</td>\n",
       "      <td>0.00380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4473.403739</td>\n",
       "      <td>1.521679</td>\n",
       "      <td>1.308139</td>\n",
       "      <td>1.159154</td>\n",
       "      <td>1.441235</td>\n",
       "      <td>1.182935</td>\n",
       "      <td>1.307311</td>\n",
       "      <td>1.077430</td>\n",
       "      <td>1.259064</td>\n",
       "      <td>1.155198</td>\n",
       "      <td>...</td>\n",
       "      <td>0.913811</td>\n",
       "      <td>0.631083</td>\n",
       "      <td>0.487814</td>\n",
       "      <td>0.594430</td>\n",
       "      <td>0.428171</td>\n",
       "      <td>0.562793</td>\n",
       "      <td>0.410868</td>\n",
       "      <td>0.266247</td>\n",
       "      <td>184.486158</td>\n",
       "      <td>0.06153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-27.670569</td>\n",
       "      <td>-34.607649</td>\n",
       "      <td>-15.496222</td>\n",
       "      <td>-4.657545</td>\n",
       "      <td>-32.092129</td>\n",
       "      <td>-23.496714</td>\n",
       "      <td>-26.548144</td>\n",
       "      <td>-23.632502</td>\n",
       "      <td>-6.329801</td>\n",
       "      <td>...</td>\n",
       "      <td>-11.468435</td>\n",
       "      <td>-8.527145</td>\n",
       "      <td>-15.144340</td>\n",
       "      <td>-2.512377</td>\n",
       "      <td>-2.577363</td>\n",
       "      <td>-1.338556</td>\n",
       "      <td>-7.976100</td>\n",
       "      <td>-3.509250</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2072.750000</td>\n",
       "      <td>-1.013283</td>\n",
       "      <td>-0.208342</td>\n",
       "      <td>0.412799</td>\n",
       "      <td>-0.614424</td>\n",
       "      <td>-0.643390</td>\n",
       "      <td>-0.629934</td>\n",
       "      <td>-0.542336</td>\n",
       "      <td>-0.190747</td>\n",
       "      <td>0.070868</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.268120</td>\n",
       "      <td>-0.549638</td>\n",
       "      <td>-0.174120</td>\n",
       "      <td>-0.327817</td>\n",
       "      <td>-0.158137</td>\n",
       "      <td>-0.327974</td>\n",
       "      <td>-0.084489</td>\n",
       "      <td>-0.015753</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4563.500000</td>\n",
       "      <td>-0.372799</td>\n",
       "      <td>0.288524</td>\n",
       "      <td>0.944361</td>\n",
       "      <td>0.219861</td>\n",
       "      <td>-0.152769</td>\n",
       "      <td>-0.152566</td>\n",
       "      <td>-0.055585</td>\n",
       "      <td>0.012865</td>\n",
       "      <td>0.805275</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.123273</td>\n",
       "      <td>-0.136746</td>\n",
       "      <td>-0.045794</td>\n",
       "      <td>0.079976</td>\n",
       "      <td>0.121001</td>\n",
       "      <td>0.042865</td>\n",
       "      <td>-0.004568</td>\n",
       "      <td>0.015897</td>\n",
       "      <td>15.950000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>10233.250000</td>\n",
       "      <td>1.150864</td>\n",
       "      <td>0.901879</td>\n",
       "      <td>1.602903</td>\n",
       "      <td>1.125666</td>\n",
       "      <td>0.371081</td>\n",
       "      <td>0.505357</td>\n",
       "      <td>0.476280</td>\n",
       "      <td>0.274533</td>\n",
       "      <td>1.506299</td>\n",
       "      <td>...</td>\n",
       "      <td>0.032707</td>\n",
       "      <td>0.247490</td>\n",
       "      <td>0.081665</td>\n",
       "      <td>0.410877</td>\n",
       "      <td>0.359058</td>\n",
       "      <td>0.476394</td>\n",
       "      <td>0.120811</td>\n",
       "      <td>0.077182</td>\n",
       "      <td>50.960000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>15012.000000</td>\n",
       "      <td>1.960497</td>\n",
       "      <td>8.636214</td>\n",
       "      <td>4.101716</td>\n",
       "      <td>10.463020</td>\n",
       "      <td>34.099309</td>\n",
       "      <td>21.393069</td>\n",
       "      <td>34.303177</td>\n",
       "      <td>5.060381</td>\n",
       "      <td>10.392889</td>\n",
       "      <td>...</td>\n",
       "      <td>22.588989</td>\n",
       "      <td>4.534454</td>\n",
       "      <td>13.876221</td>\n",
       "      <td>3.200201</td>\n",
       "      <td>5.525093</td>\n",
       "      <td>3.517346</td>\n",
       "      <td>8.254376</td>\n",
       "      <td>4.860769</td>\n",
       "      <td>7712.430000</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Time            V1            V2            V3            V4  \\\n",
       "count  10000.000000  10000.000000  10000.000000  10000.000000  10000.000000   \n",
       "mean    5966.033400     -0.241862      0.281949      0.906270      0.264148   \n",
       "std     4473.403739      1.521679      1.308139      1.159154      1.441235   \n",
       "min        0.000000    -27.670569    -34.607649    -15.496222     -4.657545   \n",
       "25%     2072.750000     -1.013283     -0.208342      0.412799     -0.614424   \n",
       "50%     4563.500000     -0.372799      0.288524      0.944361      0.219861   \n",
       "75%    10233.250000      1.150864      0.901879      1.602903      1.125666   \n",
       "max    15012.000000      1.960497      8.636214      4.101716     10.463020   \n",
       "\n",
       "                 V5            V6            V7            V8            V9  \\\n",
       "count  10000.000000  10000.000000  10000.000000  10000.000000  10000.000000   \n",
       "mean      -0.046398      0.133108     -0.071689     -0.064778      0.802224   \n",
       "std        1.182935      1.307311      1.077430      1.259064      1.155198   \n",
       "min      -32.092129    -23.496714    -26.548144    -23.632502     -6.329801   \n",
       "25%       -0.643390     -0.629934     -0.542336     -0.190747      0.070868   \n",
       "50%       -0.152769     -0.152566     -0.055585      0.012865      0.805275   \n",
       "75%        0.371081      0.505357      0.476280      0.274533      1.506299   \n",
       "max       34.099309     21.393069     34.303177      5.060381     10.392889   \n",
       "\n",
       "       ...           V21           V22           V23           V24  \\\n",
       "count  ...  10000.000000  10000.000000  10000.000000  10000.000000   \n",
       "mean   ...     -0.051990     -0.152671     -0.033268      0.021335   \n",
       "std    ...      0.913811      0.631083      0.487814      0.594430   \n",
       "min    ...    -11.468435     -8.527145    -15.144340     -2.512377   \n",
       "25%    ...     -0.268120     -0.549638     -0.174120     -0.327817   \n",
       "50%    ...     -0.123273     -0.136746     -0.045794      0.079976   \n",
       "75%    ...      0.032707      0.247490      0.081665      0.410877   \n",
       "max    ...     22.588989      4.534454     13.876221      3.200201   \n",
       "\n",
       "                V25           V26           V27           V28        Amount  \\\n",
       "count  10000.000000  10000.000000  10000.000000  10000.000000  10000.000000   \n",
       "mean       0.087146      0.108140      0.005518      0.002915     63.030188   \n",
       "std        0.428171      0.562793      0.410868      0.266247    184.486158   \n",
       "min       -2.577363     -1.338556     -7.976100     -3.509250      0.000000   \n",
       "25%       -0.158137     -0.327974     -0.084489     -0.015753      5.000000   \n",
       "50%        0.121001      0.042865     -0.004568      0.015897     15.950000   \n",
       "75%        0.359058      0.476394      0.120811      0.077182     50.960000   \n",
       "max        5.525093      3.517346      8.254376      4.860769   7712.430000   \n",
       "\n",
       "             Class  \n",
       "count  10000.00000  \n",
       "mean       0.00380  \n",
       "std        0.06153  \n",
       "min        0.00000  \n",
       "25%        0.00000  \n",
       "50%        0.00000  \n",
       "75%        0.00000  \n",
       "max        1.00000  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=42)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define X and y\n",
    "X = data.drop(columns='Class')\n",
    "y = data['Class']\n",
    "\n",
    "# Train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=.25, random_state=1)\n",
    "# Scale the data for modeling\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_sc = scaler.transform(X_train)\n",
    "X_test_sc = scaler.transform(X_test)\n",
    "\n",
    "# Train a logistic regresssion model with the train data\n",
    "cred_model = LogisticRegression(random_state=42)\n",
    "cred_model.fit(X_train_sc, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9988"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cred_model.score(X_test_sc, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We got 99.88% accuracy, meaning that 99.88% of our predictions were correct! That seems great, right? Maybe... too great? Let's dig in deeper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(cred_model, X_test_sc, y_test);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5714285714285714"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_preds = cred_model.predict(X_test_sc)\n",
    "recall_score(y_test, test_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Discuss: What do you notice?\n",
    "\n",
    "- \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class Imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    7469\n",
       "1      31\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What does a class imbalance look like?\n",
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why do we care?\n",
    "\n",
    "Think about it - you're asking a computer, which has NO idea what you're talking about or how to identify anything in any way other than how you tell it to identify things, to look at something completely new and categorize it. If you feed it 1000 emails, 950 of which are 'not spam' and 50 of which are 'spam,' and ask it to identify which are 'not spam,' it can just label everything as 'not spam' and be 95% correct! Not bad!\n",
    "\n",
    "And yet... that doesn't do what you want at all. You want your model to learn the characteristics of 'spam' emails and actually identify the parts of it which are reliable predictors for 'spam' in general, something the computer is increasingly incentivized not to do as the majority in your datasets gets larger compared to the minority. If your target is really imbalanced, your model will have to work increasingly harder in order to do better than the model-less baseline of just predicting the majority class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What can we do about it?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Under-Sampling\n",
    "\n",
    "Basically, take a sample to reduce the majority class to be the same size as the minority class.\n",
    "\n",
    "Example:\n",
    "```\n",
    "minority = df.loc[df[\"category\"] == \"minority\"]\n",
    "majority = df.loc[df[\"category\"] == \"majority\"].sample(n=len(minority))\n",
    "```\n",
    "\n",
    "Problems?\n",
    "\n",
    "- Losing a lot of observations (in the 50 spam vs 950 not-spam example, we'd lose 900 rows!)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Over-Sampling\n",
    "\n",
    "The opposite - keep resampling from our minority class until it's the same size as the majority class.\n",
    "\n",
    "Example:\n",
    "```\n",
    "majority = df.loc[df[\"category\"] == \"majority\"]\n",
    "minority = df.loc[df[\"category\"] == \"minority\"].sample(n=len(majority), replace=True)\n",
    "```\n",
    "\n",
    "Problems?\n",
    "\n",
    "- Will over-fit to the minority class, since it'll see the same minority examples over and over again (in the same 50 spam vs 950 not-spam example, we'd likely repeat each of the rows in the minority class 19 times!)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split The Difference\n",
    "\n",
    "Basically, balance Under and Over sampling so that you do a bit of both - might be better than relying on just one of the above strategies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing Over-Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, train test split\n",
    "# We only implement these techniques on training data!\n",
    "X = data.drop(columns='Class')\n",
    "y = data['Class']\n",
    "\n",
    "X_tr_samp, X_te_samp, y_tr_samp, y_te_samp = train_test_split(\n",
    "    X, y, test_size=.25, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>651</th>\n",
       "      <td>492.0</td>\n",
       "      <td>-0.789890</td>\n",
       "      <td>-1.379371</td>\n",
       "      <td>0.171334</td>\n",
       "      <td>-1.636756</td>\n",
       "      <td>-2.807266</td>\n",
       "      <td>0.726236</td>\n",
       "      <td>2.737602</td>\n",
       "      <td>-0.933999</td>\n",
       "      <td>-2.413730</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.256231</td>\n",
       "      <td>0.167077</td>\n",
       "      <td>0.540876</td>\n",
       "      <td>0.067496</td>\n",
       "      <td>0.479636</td>\n",
       "      <td>-0.098230</td>\n",
       "      <td>0.053527</td>\n",
       "      <td>-0.408050</td>\n",
       "      <td>632.40</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6560</th>\n",
       "      <td>7949.0</td>\n",
       "      <td>-0.944392</td>\n",
       "      <td>1.120606</td>\n",
       "      <td>1.943698</td>\n",
       "      <td>0.438131</td>\n",
       "      <td>0.357940</td>\n",
       "      <td>-0.524502</td>\n",
       "      <td>0.527956</td>\n",
       "      <td>-0.234039</td>\n",
       "      <td>0.785934</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.412873</td>\n",
       "      <td>-0.845279</td>\n",
       "      <td>-0.195698</td>\n",
       "      <td>0.212402</td>\n",
       "      <td>-0.030611</td>\n",
       "      <td>0.138765</td>\n",
       "      <td>-0.189770</td>\n",
       "      <td>-0.062716</td>\n",
       "      <td>3.59</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8974</th>\n",
       "      <td>12399.0</td>\n",
       "      <td>1.168740</td>\n",
       "      <td>-0.180544</td>\n",
       "      <td>0.741365</td>\n",
       "      <td>0.283013</td>\n",
       "      <td>-0.611288</td>\n",
       "      <td>-0.057707</td>\n",
       "      <td>-0.511689</td>\n",
       "      <td>0.094057</td>\n",
       "      <td>1.881734</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.181691</td>\n",
       "      <td>-0.053286</td>\n",
       "      <td>0.004593</td>\n",
       "      <td>0.247339</td>\n",
       "      <td>0.270206</td>\n",
       "      <td>1.075329</td>\n",
       "      <td>-0.084131</td>\n",
       "      <td>-0.019860</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2348</th>\n",
       "      <td>1892.0</td>\n",
       "      <td>-2.183004</td>\n",
       "      <td>-0.401099</td>\n",
       "      <td>0.864277</td>\n",
       "      <td>1.256849</td>\n",
       "      <td>0.797138</td>\n",
       "      <td>-1.377806</td>\n",
       "      <td>0.372290</td>\n",
       "      <td>-0.286859</td>\n",
       "      <td>0.095818</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.098498</td>\n",
       "      <td>0.477961</td>\n",
       "      <td>0.509126</td>\n",
       "      <td>0.388621</td>\n",
       "      <td>-0.052237</td>\n",
       "      <td>-0.316810</td>\n",
       "      <td>-0.024000</td>\n",
       "      <td>0.568065</td>\n",
       "      <td>21.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5670</th>\n",
       "      <td>5930.0</td>\n",
       "      <td>-1.788635</td>\n",
       "      <td>-1.712669</td>\n",
       "      <td>0.986718</td>\n",
       "      <td>-1.975763</td>\n",
       "      <td>2.219729</td>\n",
       "      <td>-1.987765</td>\n",
       "      <td>-0.805166</td>\n",
       "      <td>0.061549</td>\n",
       "      <td>1.989917</td>\n",
       "      <td>...</td>\n",
       "      <td>0.104806</td>\n",
       "      <td>-0.087014</td>\n",
       "      <td>0.216295</td>\n",
       "      <td>-0.540503</td>\n",
       "      <td>-0.149504</td>\n",
       "      <td>-0.229080</td>\n",
       "      <td>0.006315</td>\n",
       "      <td>0.167245</td>\n",
       "      <td>26.64</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Time        V1        V2        V3        V4        V5        V6  \\\n",
       "651     492.0 -0.789890 -1.379371  0.171334 -1.636756 -2.807266  0.726236   \n",
       "6560   7949.0 -0.944392  1.120606  1.943698  0.438131  0.357940 -0.524502   \n",
       "8974  12399.0  1.168740 -0.180544  0.741365  0.283013 -0.611288 -0.057707   \n",
       "2348   1892.0 -2.183004 -0.401099  0.864277  1.256849  0.797138 -1.377806   \n",
       "5670   5930.0 -1.788635 -1.712669  0.986718 -1.975763  2.219729 -1.987765   \n",
       "\n",
       "            V7        V8        V9  ...       V21       V22       V23  \\\n",
       "651   2.737602 -0.933999 -2.413730  ... -0.256231  0.167077  0.540876   \n",
       "6560  0.527956 -0.234039  0.785934  ... -0.412873 -0.845279 -0.195698   \n",
       "8974 -0.511689  0.094057  1.881734  ... -0.181691 -0.053286  0.004593   \n",
       "2348  0.372290 -0.286859  0.095818  ... -0.098498  0.477961  0.509126   \n",
       "5670 -0.805166  0.061549  1.989917  ...  0.104806 -0.087014  0.216295   \n",
       "\n",
       "           V24       V25       V26       V27       V28  Amount  Class  \n",
       "651   0.067496  0.479636 -0.098230  0.053527 -0.408050  632.40      0  \n",
       "6560  0.212402 -0.030611  0.138765 -0.189770 -0.062716    3.59      0  \n",
       "8974  0.247339  0.270206  1.075329 -0.084131 -0.019860    3.30      0  \n",
       "2348  0.388621 -0.052237 -0.316810 -0.024000  0.568065   21.50      0  \n",
       "5670 -0.540503 -0.149504 -0.229080  0.006315  0.167245   26.64      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Need to put our training data back together\n",
    "train_data = X_tr_samp.copy()\n",
    "train_data['Class'] = y_tr_samp\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14938, 31)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's try over-sampling our minority class and see how we do\n",
    "# Copy the provided code above, then adjust to our context\n",
    "majority = train_data.loc[train_data[\"Class\"] == 0]\n",
    "minority = train_data.loc[train_data[\"Class\"] == 1].sample(n=len(majority), replace=True)\n",
    "\n",
    "# Then use pd.concat to combine, resetting the index using .reset_index(drop=True)\n",
    "oversampled_train = pd.concat([majority, minority]).reset_index(drop=True)\n",
    "oversampled_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split out oversampled_train back out into X and y\n",
    "X_tr_oversamp = oversampled_train.drop(columns='Class')\n",
    "y_tr_oversamp = oversampled_train['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=42)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scale the data for modeling\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_tr_oversamp)\n",
    "X_tr_over_sc = scaler.transform(X_tr_oversamp)\n",
    "X_te_sc = scaler.transform(X_te_samp)\n",
    "\n",
    "# Train a logistic regresssion model with the train data\n",
    "over_model = LogisticRegression(random_state=42)\n",
    "over_model.fit(X_tr_over_sc, y_tr_oversamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9988"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "over_model.score(X_te_sc, y_te_samp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(over_model, X_te_sc, y_te_samp);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Discuss:\n",
    "\n",
    "- \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Synthetic Data Creation - ADASYN and SMOTE\n",
    "\n",
    "The **Synthetic Minority Oversampling Technique (SMOTE)** conducts cluster-based over-sampling. SMOTE works by finding all the instances of the minority category within the observations, drawing lines between those instances, and then creating new observations along those lines.\n",
    "\n",
    "![SMOTE visualized](images/SMOTE_R_visualisation_3.png)\n",
    "\n",
    "Image source is a great explainer on SMOTE (but uses R for the examples): https://rikunert.com/SMOTE_explained\n",
    "\n",
    "This is better than simply using a random over-sample, yet not only are these synthetic samples not real data but also these samples are based on your existing minority. So, those new, synthetic samples can still result in over-fitting, since they're made from our original minority category. An additional pitfall you might run into is if one of your minority category is an outlier - you'll have new data that creates synthetic data based on the line between that outlier and another point in your minority, and maybe that new synthetic data point is also an outlier.\n",
    "\n",
    "Another way to create synthetic data to over-sample our minority category is the **Adaptive Synthetic approach, ADASYN**. ADASYN works similarly to SMOTE, but it focuses on the points in the minority cluster which are the closest to the majority cluster, aka the ones that are most likely to be confused, and focuses on those. It tries to help out your model by focusing on where it might get confused, where 'spam' and 'not spam' are the closest, and making more data in your 'spam' minority category there.\n",
    "\n",
    "\n",
    "Check out the library [imblearn](https://imbalanced-learn.org/stable/) for implementation of these!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing SMOTE:\n",
    "\n",
    "https://imbalanced-learn.org/stable/references/generated/imblearn.over_sampling.SMOTE.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reminder: go back to our original train/test split:\n",
    "\n",
    "```\n",
    "X_tr_samp, X_te_samp, y_tr_samp, y_te_samp\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New import - note, not SKLearn!\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit on the training data! X_tr_samp, y_tr_samp\n",
    "# Still need to scale\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_tr_samp)\n",
    "X_tr_sc = scaler.transform(X_tr_samp)\n",
    "X_te_sc = scaler.transform(X_te_samp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate our SMOTE\n",
    "sm = SMOTE(random_state=42)\n",
    "\n",
    "X_tr_smote, y_tr_smote = sm.fit_resample(X_tr_sc, y_tr_samp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14938, 30)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tr_smote.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=42)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train a logistic regresssion model with the train data\n",
    "smote_model = LogisticRegression(random_state=42)\n",
    "smote_model.fit(X_tr_smote, y_tr_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9996"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smote_model.score(X_te_sc, y_te_samp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(smote_model, X_te_sc, y_te_samp);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Discuss:\n",
    "\n",
    "- \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One More Trick: `class_weight='balanced'`\n",
    "\n",
    "And then, of course, sklearn has some methods to handle imbalanced datasets built right into some models - including logistic regression!\n",
    "\n",
    "Check out the documentation to find it: https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reminder: go back to our original train/test split:\n",
    "\n",
    "```\n",
    "X_tr_samp, X_te_samp, y_tr_samp, y_te_samp\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try a model with an adjusted hyperparameter...\n",
    "logreg_b = LogisticRegression(class_weight='balanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the data for modeling\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_tr_samp)\n",
    "X_tr_sc = scaler.transform(X_tr_samp)\n",
    "X_te_sc = scaler.transform(X_te_samp)\n",
    "\n",
    "# Now, fitting our model and grabbing our training and testing predictions\n",
    "logreg_b.fit(X_tr_sc, y_tr_samp)\n",
    "\n",
    "train_preds = logreg_b.predict(X_tr_sc)\n",
    "test_preds = logreg_b.predict(X_te_sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting the confusion matrix using SKLearn\n",
    "plot_confusion_matrix(logreg_b, X_te_sc, y_te_samp);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\n",
      "========\n",
      "TRAIN: 1.0000\n",
      "TEST: 0.9988\n",
      "***************\n",
      "Recall:\n",
      "======\n",
      "TRAIN: 1.0000\n",
      "TEST: 0.8571\n",
      "***************\n",
      "Precision:\n",
      "=========\n",
      "TRAIN: 1.0000\n",
      "TEST: 0.7500\n",
      "***************\n",
      "F1-Score:\n",
      "========\n",
      "TRAIN: 1.0000\n",
      "TEST: 0.8000\n",
      "***************\n"
     ]
    }
   ],
   "source": [
    "# Printing the metrics nicely\n",
    "metrics = {\"Accuracy\": accuracy_score,\n",
    "           \"Recall\": recall_score,\n",
    "           \"Precision\": precision_score,\n",
    "           \"F1-Score\": f1_score}\n",
    "\n",
    "for name, metric in metrics.items():\n",
    "    print(f\"{name}:\"); print(\"=\"*len(name))\n",
    "    print(f\"TRAIN: {metric(y_tr_samp, train_preds):.4f}\")\n",
    "    print(f\"TEST: {metric(y_te_samp, test_preds):.4f}\")\n",
    "    print(\"*\" * 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resources:\n",
    "\n",
    "- [SMOTE Explained for Noobs](https://rikunert.com/SMOTE_explained) (the R tutorial I linked earlier)\n",
    "- [Resampling Strategies for Imbalanced Datasets](https://www.kaggle.com/rafjaa/resampling-strategies-for-imbalanced-datasets)\n",
    "- Machine Learning Mastery: [8 Tactics to Combat Imbalanced Classes in Your Machine Learning Dataset](https://machinelearningmastery.com/tactics-to-combat-imbalanced-classes-in-your-machine-learning-dataset/)\n",
    "- [Handling Imbalanced Datasets in Deep Learning](https://towardsdatascience.com/handling-imbalanced-datasets-in-deep-learning-f48407a0e758)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
