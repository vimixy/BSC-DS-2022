{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "# Model Validation and Data Leakage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- explain the bias-variance tradeoff and the notions of underfit and overfit models\n",
    "- describe a train-test split and explain its purpose in the context of predictive statistics / machine learning\n",
    "\n",
    "Bonus: evaluate models using other regression metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Motivation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "At this point, we have seen different ways to create models from our data through different linear regression techniques. That's good. But when it comes to measuring model performance, we also want to make sure that our models are ready to predict _on data that they haven't seen yet_.\n",
    "\n",
    "Usually, when our model is ready to be used in the \"real world\" we refer to this as putting our model into **production** or **deploying** our model. The data points for which it will make predictions will be data *it has never seen before*, as opposed to the data points that were used to train the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "This is where ***model validation*** techniques come in, namely, to ensure our model can *generalize* to data it hasn't directly seen before.\n",
    "\n",
    "As a way into a discussion of these techniques let's say a word about the **bias-variance tradeoff**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## The Bias-Variance Tradeoff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We can break up how the model makes mistakes (the error) by saying there are three parts:\n",
    "\n",
    "- Error inherent in the data (noise): **irreducible error**\n",
    "- Error from not capturing signal (too simple): **bias**\n",
    "- Error from \"modeling noise\", i.e. capturing patterns in the data that don't generalize well (too complex): **variance**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We can summarize this in an equation for the _mean squared error_ (MSE):\n",
    "\n",
    "$MSE = Bias(\\hat{y})^2 + Var(\\hat{y}) + \\sigma^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<img src=\"images/optimal_bias_variance.png\" alt=\"image source: http://scott.fortmann-roe.com/docs/BiasVariance.html\" width=600>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**High-bias** algorithms tend to be less complex, with simple or rigid underlying structure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<img src=\"images/noisy-sine-linear.png\" width=400>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "+ They train models that are consistent, but inaccurate on average.\n",
    "+ These include linear or parametric algorithms such as regression and naive Bayes.\n",
    "+ The following sorts of difficulties could lead to high bias:\n",
    "  - We did not include the correct predictors\n",
    "  - We did not take interactions into account\n",
    "  - We missed a non-linear (polynomial) relationship"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "      \n",
    "High-bias models are generally **underfit**: The models have not picked up enough of the signal in the data. And so even though they may be consistent, they don't perform particularly well on the initial data, and so they will be consistently inaccurate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "On the other hand, **high-variance** algorithms tend to be more complex, with flexible underlying structure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<img src=\"images/noisy-sine-decision-tree.png\" width=400>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "+ They train models that are accurate on average, but inconsistent.\n",
    "+ These include non-linear or non-parametric algorithms such as decision trees and nearest-neighbor models.\n",
    "+ The following sorts of difficulties could lead to high variance:\n",
    "  - We included an unreasonably large number of predictors;\n",
    "  - We created new features by squaring and cubing each feature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "High variance models are **overfit**: The models have picked up on the noise as well as the signal in the data. And so even though they may perform well on the initial data, they will be inconsistently accurate on new data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Balancing Bias and Variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "While we build our models, we have to keep this relationship in mind.  If we build overly complex models, we risk overfitting our models.  Their predictions will vary greatly when introduced to new data.  If our models are too simple, the predictions as a whole will be inaccurate.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<img src=\"images/noisy-sine-third-order-polynomial.png\" width=450>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The goal is to build a model with enough complexity to be accurate, but not too much complexity to be erratic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How To Minimize Bias and Variance\n",
    "\n",
    "### Combat Underfitting (Bias)\n",
    "\n",
    "**Bias**: Error introduced by approximating a real-life problem (which may be extremely complicated) by a much simpler model (because the model is too simple to capture the underlying pattern)\n",
    "\n",
    "**The Solution:** evaluate the performance of our models, using a scoring metric, which will help us catch if a model is underfit - if it's performing quite poorly, it probably isn't capturing the relationship in our data! \n",
    "\n",
    "### Combat Overfitting (Variance)\n",
    "\n",
    "**Variance**: Amount by which our model would change if we estimated it using a different training dataset (because the model is over-learning from the training data)\n",
    "\n",
    "**The Solution:** don't train your model on ALL of your data, but keep some of it in reserve to test on, in order to simulate how it will work on new/incoming data.\n",
    "\n",
    "\n",
    "<img alt=\"original image from https://www.dataquest.io/wp-content/uploads/kaggle_train_test_split.svg plus some added commentary\" src=\"images/traintestsplit_80-20.png\" width=650, height=150>  \n",
    "\n",
    "How does this fight against overfitting? By witholding data from the training process, we are testing whether the model actually _generalizes_ well. If it does poorly on the test set, it's a good sign that our model learned too much noise from the train set and is overfit! \n",
    "\n",
    "![arrested development gif, found by Andy](https://heavy.com/wp-content/uploads/2013/05/tumblr_mjm9fqhrle1rvnnvyo6_250.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time to Train Test Split!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's practice with credit data from https://www.kaggle.com/avikpaul4u/credit-card-balance\n",
    "\n",
    "Target: `Balance`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data\n",
    "df = pd.read_csv('data/Credit.csv', \n",
    "                 usecols=['Income', 'Limit', 'Rating', 'Cards', 'Age', 'Balance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Income</th>\n",
       "      <th>Limit</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Cards</th>\n",
       "      <th>Age</th>\n",
       "      <th>Balance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.891</td>\n",
       "      <td>3606</td>\n",
       "      <td>283</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>106.025</td>\n",
       "      <td>6645</td>\n",
       "      <td>483</td>\n",
       "      <td>3</td>\n",
       "      <td>82</td>\n",
       "      <td>903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>104.593</td>\n",
       "      <td>7075</td>\n",
       "      <td>514</td>\n",
       "      <td>4</td>\n",
       "      <td>71</td>\n",
       "      <td>580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>148.924</td>\n",
       "      <td>9504</td>\n",
       "      <td>681</td>\n",
       "      <td>3</td>\n",
       "      <td>36</td>\n",
       "      <td>964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>55.882</td>\n",
       "      <td>4897</td>\n",
       "      <td>357</td>\n",
       "      <td>2</td>\n",
       "      <td>68</td>\n",
       "      <td>331</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Income  Limit  Rating  Cards  Age  Balance\n",
       "0   14.891   3606     283      2   34      333\n",
       "1  106.025   6645     483      3   82      903\n",
       "2  104.593   7075     514      4   71      580\n",
       "3  148.924   9504     681      3   36      964\n",
       "4   55.882   4897     357      2   68      331"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Income</th>\n",
       "      <th>Limit</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Cards</th>\n",
       "      <th>Age</th>\n",
       "      <th>Balance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>400.000000</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>400.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>45.218885</td>\n",
       "      <td>4735.600000</td>\n",
       "      <td>354.940000</td>\n",
       "      <td>2.957500</td>\n",
       "      <td>55.667500</td>\n",
       "      <td>520.015000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>35.244273</td>\n",
       "      <td>2308.198848</td>\n",
       "      <td>154.724143</td>\n",
       "      <td>1.371275</td>\n",
       "      <td>17.249807</td>\n",
       "      <td>459.758877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>10.354000</td>\n",
       "      <td>855.000000</td>\n",
       "      <td>93.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>21.007250</td>\n",
       "      <td>3088.000000</td>\n",
       "      <td>247.250000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>41.750000</td>\n",
       "      <td>68.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>33.115500</td>\n",
       "      <td>4622.500000</td>\n",
       "      <td>344.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>459.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>57.470750</td>\n",
       "      <td>5872.750000</td>\n",
       "      <td>437.250000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>863.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>186.634000</td>\n",
       "      <td>13913.000000</td>\n",
       "      <td>982.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>1999.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Income         Limit      Rating       Cards         Age  \\\n",
       "count  400.000000    400.000000  400.000000  400.000000  400.000000   \n",
       "mean    45.218885   4735.600000  354.940000    2.957500   55.667500   \n",
       "std     35.244273   2308.198848  154.724143    1.371275   17.249807   \n",
       "min     10.354000    855.000000   93.000000    1.000000   23.000000   \n",
       "25%     21.007250   3088.000000  247.250000    2.000000   41.750000   \n",
       "50%     33.115500   4622.500000  344.000000    3.000000   56.000000   \n",
       "75%     57.470750   5872.750000  437.250000    4.000000   70.000000   \n",
       "max    186.634000  13913.000000  982.000000    9.000000   98.000000   \n",
       "\n",
       "           Balance  \n",
       "count   400.000000  \n",
       "mean    520.015000  \n",
       "std     459.758877  \n",
       "min       0.000000  \n",
       "25%      68.750000  \n",
       "50%     459.500000  \n",
       "75%     863.000000  \n",
       "max    1999.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should split your data into training and testing data _early_ in the process - ideally even before you've done a lot of data exploration! \n",
    "\n",
    "**FOR THE PROJECT, YOU WILL BE _REQUIRED_ TO WORK WITH A TRAIN TEST SPLIT**\n",
    "\n",
    "Note - for checkpoints and the code challenge, follow the instructions given - they might not require a train/test split as they attempt to keep thing simple.\n",
    "\n",
    "BUT we're going to use it in this session! Let's see what this looks like in practice!\n",
    "\n",
    "[Documentation for the train-test split function](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the train_test_split function from sklearn\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to define our X and y\n",
    "X = df.drop(columns='Balance')\n",
    "y = df['Balance']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train test split here!\n",
    "# Set test_size = .33\n",
    "# Set random_state = 42\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What did that do?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(268, 5)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(132, 5)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train + X_test) == len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Income</th>\n",
       "      <th>Limit</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Cards</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>41.400</td>\n",
       "      <td>2561</td>\n",
       "      <td>215</td>\n",
       "      <td>2</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>22.379</td>\n",
       "      <td>3965</td>\n",
       "      <td>292</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>23.012</td>\n",
       "      <td>1410</td>\n",
       "      <td>137</td>\n",
       "      <td>3</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>30.406</td>\n",
       "      <td>2120</td>\n",
       "      <td>181</td>\n",
       "      <td>2</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>69.943</td>\n",
       "      <td>7555</td>\n",
       "      <td>547</td>\n",
       "      <td>3</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Income  Limit  Rating  Cards  Age\n",
       "258  41.400   2561     215      2   36\n",
       "177  22.379   3965     292      2   34\n",
       "119  23.012   1410     137      3   81\n",
       "194  30.406   2120     181      2   79\n",
       "229  69.943   7555     547      3   76"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "258       0\n",
       "177     384\n",
       "119       0\n",
       "194       0\n",
       "229    1058\n",
       "Name: Balance, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.index == y_train.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time to Model!\n",
    "\n",
    "Pick your poison: would you like to start with the kitchen sink approach, or choose one variable to model against `Balance`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If simple model - would want to see what correlates with target\n",
    "train_df = X_train.copy()\n",
    "\n",
    "train_df['target'] = y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(train_df.corr(), annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target    1.000000\n",
       "Rating    0.880719\n",
       "Limit     0.880302\n",
       "Income    0.501414\n",
       "Cards     0.120045\n",
       "Age       0.000781\n",
       "Name: target, dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.corr()['target'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_model = sm.OLS(y_train, sm.add_constant(X_train['Rating'])).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>Balance</td>     <th>  R-squared:         </th> <td>   0.776</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.775</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   919.7</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 22 Jun 2022</td> <th>  Prob (F-statistic):</th> <td>2.59e-88</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>13:54:35</td>     <th>  Log-Likelihood:    </th> <td> -1830.3</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   268</td>      <th>  AIC:               </th> <td>   3665.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   266</td>      <th>  BIC:               </th> <td>   3672.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "     <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>  <td> -399.0605</td> <td>   33.857</td> <td>  -11.787</td> <td> 0.000</td> <td> -465.723</td> <td> -332.398</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Rating</th> <td>    2.6205</td> <td>    0.086</td> <td>   30.327</td> <td> 0.000</td> <td>    2.450</td> <td>    2.791</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>17.496</td> <th>  Durbin-Watson:     </th> <td>   2.065</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td>  34.301</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.333</td> <th>  Prob(JB):          </th> <td>3.56e-08</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 4.621</td> <th>  Cond. No.          </th> <td>    967.</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                Balance   R-squared:                       0.776\n",
       "Model:                            OLS   Adj. R-squared:                  0.775\n",
       "Method:                 Least Squares   F-statistic:                     919.7\n",
       "Date:                Wed, 22 Jun 2022   Prob (F-statistic):           2.59e-88\n",
       "Time:                        13:54:35   Log-Likelihood:                -1830.3\n",
       "No. Observations:                 268   AIC:                             3665.\n",
       "Df Residuals:                     266   BIC:                             3672.\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const       -399.0605     33.857    -11.787      0.000    -465.723    -332.398\n",
       "Rating         2.6205      0.086     30.327      0.000       2.450       2.791\n",
       "==============================================================================\n",
       "Omnibus:                       17.496   Durbin-Watson:                   2.065\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               34.301\n",
       "Skew:                           0.333   Prob(JB):                     3.56e-08\n",
       "Kurtosis:                       4.621   Cond. No.                         967.\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If kitchen sink - should scale first!\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler()"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "scaler.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>Balance</td>     <th>  R-squared:         </th> <td>   0.887</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.885</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   410.8</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 22 Jun 2022</td> <th>  Prob (F-statistic):</th> <td>9.85e-122</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>14:03:50</td>     <th>  Log-Likelihood:    </th> <td> -1738.6</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   268</td>      <th>  AIC:               </th> <td>   3489.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   262</td>      <th>  BIC:               </th> <td>   3511.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     5</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "       <td></td>          <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Y-Intercept</th> <td>  539.6343</td> <td>    9.817</td> <td>   54.967</td> <td> 0.000</td> <td>  520.303</td> <td>  558.965</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Income</th>      <td> -245.3279</td> <td>   16.442</td> <td>  -14.921</td> <td> 0.000</td> <td> -277.703</td> <td> -212.953</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Limit</th>       <td>  475.8959</td> <td>  147.989</td> <td>    3.216</td> <td> 0.001</td> <td>  184.498</td> <td>  767.294</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Rating</th>      <td>  135.5443</td> <td>  149.144</td> <td>    0.909</td> <td> 0.364</td> <td> -158.129</td> <td>  429.218</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Cards</th>       <td>   31.1953</td> <td>   11.889</td> <td>    2.624</td> <td> 0.009</td> <td>    7.785</td> <td>   54.605</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Age</th>         <td>  -15.3400</td> <td>    9.989</td> <td>   -1.536</td> <td> 0.126</td> <td>  -35.008</td> <td>    4.328</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>62.981</td> <th>  Durbin-Watson:     </th> <td>   2.062</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td> 104.460</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 1.330</td> <th>  Prob(JB):          </th> <td>2.07e-23</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 4.509</td> <th>  Cond. No.          </th> <td>    35.5</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                Balance   R-squared:                       0.887\n",
       "Model:                            OLS   Adj. R-squared:                  0.885\n",
       "Method:                 Least Squares   F-statistic:                     410.8\n",
       "Date:                Wed, 22 Jun 2022   Prob (F-statistic):          9.85e-122\n",
       "Time:                        14:03:50   Log-Likelihood:                -1738.6\n",
       "No. Observations:                 268   AIC:                             3489.\n",
       "Df Residuals:                     262   BIC:                             3511.\n",
       "Df Model:                           5                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "===============================================================================\n",
       "                  coef    std err          t      P>|t|      [0.025      0.975]\n",
       "-------------------------------------------------------------------------------\n",
       "Y-Intercept   539.6343      9.817     54.967      0.000     520.303     558.965\n",
       "Income       -245.3279     16.442    -14.921      0.000    -277.703    -212.953\n",
       "Limit         475.8959    147.989      3.216      0.001     184.498     767.294\n",
       "Rating        135.5443    149.144      0.909      0.364    -158.129     429.218\n",
       "Cards          31.1953     11.889      2.624      0.009       7.785      54.605\n",
       "Age           -15.3400      9.989     -1.536      0.126     -35.008       4.328\n",
       "==============================================================================\n",
       "Omnibus:                       62.981   Durbin-Watson:                   2.062\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              104.460\n",
       "Skew:                           1.330   Prob(JB):                     2.07e-23\n",
       "Kurtosis:                       4.509   Cond. No.                         35.5\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now model and check the summary\n",
    "sink_model = sm.OLS(y_train, sm.add_constant(X_train_scaled)).fit()\n",
    "sink_model.summary(xname=['Y-Intercept', *X.columns])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate:\n",
    "\n",
    "How'd we do?\n",
    "\n",
    "- \n",
    "\n",
    "\n",
    "But, more importantly, how can we see how we did on the test data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's use sklearn's r2_score to score our model\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to grab out model predictions\n",
    "# Don't forget to add the constant\n",
    "# ALSO! If we followed the kitchen sink approach, need to transform X_test!\n",
    "train_preds = simple_model.predict(sm.add_constant(X_train['Rating']))\n",
    "test_preds = simple_model.predict(sm.add_constant(X_test['Rating']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simple Model Train R2: 0.7756660731253149\n",
      "Simple Model Test R2: 0.6656804809053132\n"
     ]
    }
   ],
   "source": [
    "print(f\"Simple Model Train R2: {r2_score(y_train, train_preds)}\")\n",
    "print(f\"Simple Model Test R2: {r2_score(y_test, test_preds)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preds = sink_model.predict(sm.add_constant(X_train_scaled))\n",
    "test_preds = sink_model.predict(sm.add_constant(X_test_scaled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simple Model Train R2: 0.886882050887701\n",
      "Simple Model Test R2: 0.8500179616615862\n"
     ]
    }
   ],
   "source": [
    "print(f\"Simple Model Train R2: {r2_score(y_train, train_preds)}\")\n",
    "print(f\"Simple Model Test R2: {r2_score(y_test, test_preds)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate\n",
    "\n",
    "How'd we do? What do you observe?\n",
    "\n",
    "- \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##  Knowledge Check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<img src=\"images/which_model_is_better_2.png\" width=700>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Process Recap\n",
    "\n",
    "If our model is not performing well on the training data, we are probably underfitting it.  \n",
    "\n",
    "To know if our  model is overfitting the data, we need  to test our model on unseen data. We then measure our performance on the unseen data. \n",
    "\n",
    "If the model performs significantly worse on the unseen data, it is probably overfitting the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<img src='https://developers.google.com/machine-learning/crash-course/images/WorkflowWithTestSet.svg' width=500/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Should You Ever Fit on Your Test Set?  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "![no](https://media.giphy.com/media/d10dMmzqCYqQ0/giphy.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Never fit on test data.** If you are seeing surprisingly good results on your evaluation metrics, it might be a sign that you are accidentally training on the test set.\n",
    "\n",
    "This goes both for models and for preprocessing steps, like scalers!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Practice Exercises: Name that Model!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Consider the following scenarios and describe them according to bias and variance. There are four possibilities:\n",
    "\n",
    "- a. The model has low bias and high variance.\n",
    "- b. The model has high bias and low variance.\n",
    "- c. The model has both low bias and low variance.\n",
    "- d. The model has both high bias and high variance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Scenario 1**: The model has a low $R^2$ on training and a low $R^2$ on test.\n",
    "\n",
    "- \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Scenario 2**: The model has a high $R^2$ on the training set, but a low $R^2$ on the test.\n",
    "\n",
    "- \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Scenario 3**: The model performs well on data it is fit on and well on data it has not seen.\n",
    "\n",
    "- \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Scenario 4**: The model has a low $R^2$ on training but high on the test set.\n",
    "\n",
    "- \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Scenario 5**: The model leaves out many of the meaningful predictors, but is consistent across samples.\n",
    "\n",
    "- \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Scenario 6**: The model is highly sensitive to random noise in the training set.\n",
    "\n",
    "- \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra Credit: Beyond the $R^2$ Score\n",
    "\n",
    "There are other metrics! \n",
    "\n",
    "#### Mean Absolute Error (MAE)\n",
    "\n",
    "$$\\text{MAE}(y, y_\\text{pred}) = \\frac{1}{n} \\sum_{i=0}^{n} \\left| y_i - y_\\text{pred}i \\right|$$\n",
    "\n",
    "- Measures the average magnitude of errors regardless of direction, by calculating the total absolute value of errors and dividing by the number of samples (number of predictions made)\n",
    "- **This error term is in the same units as the target!**\n",
    "\n",
    "#### Mean Squared Error (MSE)\n",
    "\n",
    "$$\\text{MSE}(y, y_\\text{pred}) = \\frac{1}{n} \\sum_{i=0}^{n} (y_i - y_\\text{pred}i)^2$$\n",
    "\n",
    "- Measures the average squared error, by calculating the sum of squared errors for all predictions then dividing by the number of samples (number of predictions)\n",
    "- In other words - this is the Residual Sum of Squares (RSS) divided by the number of predictions!\n",
    "- This error term is **NOT** in the same units as the target!\n",
    "\n",
    "#### Root Mean Squared Error (RMSE)\n",
    "\n",
    "$$\\text{RMSE}(y, y_\\text{pred}) = \\sqrt{\\frac{1}{n} \\sum_{i=0}^{n} (y_i - y_\\text{pred}i)^2}$$\n",
    "\n",
    "- Measures the square root of the average squared error, by calculating the sum of squared errors for all predictions then dividing by the number of samples (number of predictions), then taking the square root of all that\n",
    "- **This error term is in the same units as the target!**\n",
    "\n",
    "Note - before, we were _maximizing_ R2 (best fit = largest R2 score). But we'd want to minimize these other error metrics.\n",
    "\n",
    "Documentation: \n",
    "- [Regression Metrics in sklearn](https://scikit-learn.org/stable/modules/classes.html#regression-metrics)\n",
    "- [User Guide for Regression Metrics in sklearn](https://scikit-learn.org/stable/modules/model_evaluation.html#regression-metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics:\n",
      "R2: 0.887\n",
      "Mean Absolute Error: 118.442\n",
      "Mean Squared Error: 25251.723\n",
      "Root Mean Squared Error: 158.908\n"
     ]
    }
   ],
   "source": [
    "# Assuming we have a train_preds variable that captures our train predictions!\n",
    "\n",
    "print(\"Metrics:\")\n",
    "# R2\n",
    "print(f\"R2: {r2_score(y_train, train_preds):.3f}\")\n",
    "# MAE\n",
    "print(f\"Mean Absolute Error: {mean_absolute_error(y_train, train_preds):.3f}\")\n",
    "# MSE\n",
    "print(f\"Mean Squared Error: {mean_squared_error(y_train, train_preds):.3f}\")\n",
    "# RMSE - just MSE but set squared=False\n",
    "print(f\"Root Mean Squared Error: {mean_squared_error(y_train, train_preds, squared=False):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that I said that MAE and RMSE are both in the same units as our target, but you'll see that they are different here. What's the difference?\n",
    "\n",
    "> \"Taking the square root of the average squared errors has some interesting implications for RMSE. Since the errors are squared before they are averaged, the RMSE gives a relatively high weight to large errors. This means the RMSE should be more useful when large errors are particularly undesirable.\"\n",
    "\n",
    "-- Source: [\"MAE and RMSE  Which Metric is Better?\"](https://medium.com/human-in-a-machine-world/mae-and-rmse-which-metric-is-better-e60ac3bde13d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How can we interpret these?\n",
    "\n",
    "- R2: \"Our model accounts for 61.2% of the variance in our target\"\n",
    "- MAE/RMSE: \"Our model's predictions are, on average, about __ off from our actual target values\" (here, balance is likely in dollars - so $___ off)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Resources:\n",
    "\n",
    "- [Excellent statistical writeup about how to interpret Linear Regression coefficients, and their p-values](https://statisticsbyjim.com/regression/interpret-coefficients-p-values-regression/)\n",
    "- [Great bias/variance infographic](https://elitedatascience.com/bias-variance-tradeoff) from Elite Data Science"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "-----\n",
    "\n",
    "## Level Up: $k$-Fold Cross-Validation: Even More Rigorous Validation  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "Our goal of using a test set is to simulate what happens when our model attempts predictions on data it's never seen before. But it's possible that our model would *by chance* perform well on the test set.\n",
    "\n",
    "This is where we could use a more rigorous validation method and turn to **$k$-fold cross-validation**.\n",
    "\n",
    "<img src=\"images/k_folds.png\" width=600>\n",
    "\n",
    "[image via sklearn](https://scikit-learn.org/stable/modules/cross_validation.html)\n",
    "\n",
    "In this process, we split the dataset into a train set and holdout test sets like usual by performing a shuffling train-test split on the train set.  \n",
    "\n",
    "We then do $k$-number of _folds_ of the training data. This means we divide the training set into different sections or folds. We then take turns on using each fold as a **validation set** (or **dev set**) and train on the larger fraction. Then we calculate a validation score from the validation set the model has never seen. We repeat this process until each fold has served as a validation set.\n",
    "\n",
    "This process allows us to try out training our model and check to see if it is likely to overfit or underfit without touching the holdout test data set.\n",
    "\n",
    "If we think the model is looking good according to our cross-validation using the training data, we retrain the model using all of the training data. Then we can do one final evaluation using the test data. \n",
    "\n",
    "It's important that we hold onto our test data until the end and refrain from making adjustments to the model based on the test results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Level Up: More on Bias and Variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### A Model Example\n",
    "\n",
    "Typically we'll talk about a model in terms of how _complex_ it is in making predictions.\n",
    "\n",
    "Let's take a look at this data with just one feature and a target:\n",
    "\n",
    "\n",
    "We can probably picture how a good model will fit to this data. Let's look at a couple models and discuss how they're making mistakes.\n",
    "\n",
    "#### Model A\n",
    "\n",
    "![](images/model_simple.png)\n",
    "\n",
    "What do we observe here? How would you describe where the model is failing?\n",
    "\n",
    "- \n",
    "\n",
    "\n",
    "#### Model B\n",
    "\n",
    "![](images/model_complex.png)\n",
    "\n",
    "What do we observe here? How would you describe where the model is failing?\n",
    "\n",
    "- \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": "1",
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "TOC",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "371px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
