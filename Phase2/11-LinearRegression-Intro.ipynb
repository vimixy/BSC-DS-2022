{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "\n",
    "- Explain and use the concepts of covariance and correlation\n",
    "- Explain how to interpret linear regressions\n",
    "- Use the `statsmodels` library to create a simple linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AKA - Welcome to statistical modeling! Could also say - welcome to **Supervised Machine Learning**.\n",
    "\n",
    "What do I mean by 'Supervised' ?\n",
    "\n",
    "![Types of machine learning, broken down](images/machinelearning_supervisedunsupervised.png)\n",
    " \n",
    "[Image Source](https://fr.mathworks.com/help/stats/machine-learning-in-matlab.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First: Some Set Up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Covariance and Correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The idea of _correlation_ is the simple idea that variables often change _together_.\n",
    "\n",
    "We might observe that, as one variable X increases, so does another Y, OR that as X increases, Y decreases.  For a simple example, cities with more buses tend to have higher populations.\n",
    "\n",
    "> \"Covariance shows you how the two variables _differ_, whereas correlation shows you how the two variables are _related_.\"\n",
    "> \n",
    "> -- [SimpliLearn: Covariance vs Correlation](https://www.simplilearn.com/covariance-vs-correlation-article)\n",
    "\n",
    "Recognizing and measuring how variables are related will come up again and again as we begin our journey into statistical modeling!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Causation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "_Why_ does it happen that variables correlate? It _may_ be that one is the cause of the other. A city having a high population, for example, probably does have some causal effect on the number of buses that the city has. But this _need not_ be the case, and that is why statisticians are fond of saying that 'correlation is not causation'. An alternative possibility, for example, is that high values of X and Y are _both_ caused by high values of some third factor Z. The size of children's feet, for example, is correlated with their ability to spell, but this is of course NOT because either is a cause of the other. Rather, BOTH are caused by the natural maturing and development of children. As they get older, both their feet and their spelling abilities grow!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Statistical Learning Theory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> \"The main goal of statistical learning theory is to provide a framework for studying the problem of inference, that is of gaining knowledge, making predictions, making decisions or constructing models from a set of data.\"\n",
    "> \n",
    "> -- [\"Introduction to Statistical Learning Theory\"](http://www.econ.upf.edu/~lugosi/mlss_slt.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "It's important at this point to understand the distinction between dependent and independent variables.\n",
    "\n",
    "Roughly, the independent variable is what can be directly manipulated and the dependent variable is what cannot be (but is nevertheless of great interest). What matters structurally is simply that we understand the dependent variable to be a _function_ of the independent variable(s).\n",
    "\n",
    "This is the proper interpretation of a statistical _model_.\n",
    "\n",
    "Here's a simple idea: We could model correlation with a _line_. As one variable changes, so does the other.\n",
    "\n",
    "This model would have two *parameters*: *slope* and *y-intercept*.\n",
    "\n",
    "Unless there's a perfectly (and suspiciously) linear relationship between our predictor(s) and our target, there will  be some sort of **error** or **loss** or **residual**. The best-fit line is constructed by minimizing the sum of the squares of these losses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Linear Regression\n",
    "\n",
    "For our first model:\n",
    "\n",
    "$$ y = m \\cdot x + b $$\n",
    "\n",
    "Here:\n",
    "\n",
    "- $x$: input column (just one for now)\n",
    "- $y$: output column (column we're trying to predict)\n",
    "\n",
    "Solving for the coefficients $m$ and $b$ - our slope and y-intercept - based on the line that 'best' represents the relationship between $x$ and $y$, _assuming_ that relationship is a straight line.\n",
    "\n",
    "(there are more assumptions too, but we'll get to those later)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A Quick Example to Show You The Ropes\n",
    "\n",
    "As an example, let's say that we assume that overall average temperature across a corn plant's lifespan has an impact on the height of that corn stalk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading in just two columns, temp and height\n",
    "# Can assume that temp is the average temp across the plant's lifespan (deg F)\n",
    "# Then height is the height at the time of measurement (cm)\n",
    "df = pd.read_csv(\"data/corn.csv\", index_col=0)[['temp', 'height']]\n",
    "\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can numerically explore their correlation using pandas\n",
    "df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# can use a scatter plot to explore relationship between 2 variables\n",
    "plt.figure(figsize=(8,6))\n",
    "\n",
    "plt.scatter(df['temp'], df['height'])\n",
    "plt.ylabel('Corn Stalk Height (cm)')\n",
    "plt.xlabel('Temperature (degrees F)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seaborn even has a 'best fit line' plot\n",
    "sns.lmplot(x='temp', y='height', data=df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But what are those parameters found by seaborn above, and how can we solve for them?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression with `statsmodels`\n",
    "\n",
    "\n",
    "[Check the documentation](http://www.statsmodels.org/devel/generated/statsmodels.regression.linear_model.OLS.html#statsmodels.regression.linear_model.OLS)\n",
    "\n",
    "Now let's use statsmodels to fit a linear model to our data.\n",
    "\n",
    "Specifically, we'll use statsmodels' OLS function:\n",
    "\n",
    "```python\n",
    "# Create a model of our data\n",
    "model = sm.OLS(y, X)\n",
    "# Fit the model to our data\n",
    "results = model.fit()\n",
    "# Then we can predict an output by passing in new inputs\n",
    "y_preds = results.predict(new_X)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, let's import statsmodels.api as sm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preparing Our Data, then Fitting Our Model\n",
    "\n",
    "We use capital `X` to capture inputs and lowercase `y` to capture the output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab our data out as X and y variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's model!\n",
    "model_no_intercept = None # creating our model\n",
    "# We're doing this specifically without an intercept constant, for the moment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_no_intercept = None # actually fitting the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_no_intercept.params # seeing our coefficients - just one, since no intercept"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Making Predictions\n",
    "\n",
    "We can make up some random points and see where they'd fall on our best fit line! \n",
    "\n",
    "AKA - if we had corn stalks that grew at tempeartures measuring 74, 41, or 99 degrees fahrenheit, how tall would we expect them to be (based on our line of best fit)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_X = [74, 41, 99]\n",
    "results_no_intercept.predict(random_X) # predicting for some random possible X values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "\n",
    "# this plots the actual data\n",
    "plt.scatter(X, y, label='Actual Values')\n",
    "\n",
    "# this plots our line of best fit between 40 and 100\n",
    "x_pred_range = np.linspace(40, 100, 100)\n",
    "plt.plot(x_pred_range, results_no_intercept.predict(x_pred_range), \n",
    "         label='\"Line of Best Fit (without intercept)\"', color='black')\n",
    "\n",
    "# Showcasing our random predictions\n",
    "plt.scatter(random_X, results_no_intercept.predict(random_X), color='red', \n",
    "            label='Random Predictions')\n",
    "\n",
    "plt.ylabel('Corn Stalk Height (cm)')\n",
    "plt.xlabel('Temperature (degrees F)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding Our Constant - AKA Our Y Intercept\n",
    "\n",
    "Okay... just one parameter though, a slope - why no intercept? Because statsmodels is weird and assumes you add a constant manually if you want one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X_with_const = None # easiest way to add the constant, using sm\n",
    "pd.DataFrame(X_with_const, columns=['ones', 'temp']).head() # showing the change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a new model\n",
    "model = None # can tell sm there's a constant\n",
    "results = None\n",
    "results.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "\n",
    "# this plots the actual data\n",
    "plt.scatter(X, y, label='Actual Values')\n",
    "\n",
    "# this plots our BETTER line of best fit between 40 and 100\n",
    "x_pred_range = np.linspace(40, 100, 100)\n",
    "plt.plot(x_pred_range, results.predict(sm.add_constant(x_pred_range)), \n",
    "         label='Line of Best Fit (Predicted Values)', color='black')\n",
    "\n",
    "# Showcasing our random predictions\n",
    "plt.scatter(random_X, results.predict(sm.add_constant(random_X)), color='red', \n",
    "            label='Random Predictions')\n",
    "# Notice how our predictions for these points have changed!\n",
    "\n",
    "plt.ylabel('Corn Stalk Height (cm)')\n",
    "plt.xlabel('Temperature (degrees F)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neat.\n",
    "\n",
    "So, uh... how'd we do?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check our work\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating Our Models - How do we know what's 'best' ?\n",
    "\n",
    "### Introducing the $R^2$ Score\n",
    "\n",
    "While there are several ways we'll learn to evaluate our linear regression models, let's start with the **R-Squared** score, aka the **Coefficient of Determination**.\n",
    "\n",
    "The easiest way to think about an R2 score is that it compares how much more variance in `y` you explain with your model compared to predicting that `y` is always the mean value.\n",
    "\n",
    "In other words, it compares our fit linear regression model to a much dumber/simpler way we could have predicted our `y` values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simple Model-less Baseline: Always Predict Our Average Y\n",
    "\n",
    "If we knew nothing about modeling, we might predict the height of a corn stalk (or whatever our dependent `y` value might be) as the average of all the corn stalk heights that we have in our data.\n",
    "\n",
    "This is a _baseline model_, specifically what I'll call a really dumb baseline model - without any actual modeling, what is the easiest way to get a really simple prediction?\n",
    "\n",
    "Let's see what this looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "# this plots the actual data\n",
    "plt.scatter(X, y)\n",
    "\n",
    "# Now plotting our average y\n",
    "plt.hlines(y=y.mean(),\n",
    "           xmin=X.min(), xmax=X.max(),\n",
    "           color='red',\n",
    "           label=f'Average Corn Stalk Height: {df[\"height\"].mean():.2f}')\n",
    "\n",
    "plt.ylabel('Corn Stalk Height (cm)')\n",
    "plt.xlabel('Temperature (degrees F)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, predicting the mean for each of these points is not explaining what is going on in the data very well. \n",
    "\n",
    "If we were to draw a line between our actual values (blue dots) and our predicted values (here, just our mean value for y every time, our dumb model-less baseline) we could capture and calculate our **errors**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's visualize those errors\n",
    "plt.figure(figsize=(8,6))\n",
    "# this plots the actual data\n",
    "plt.scatter(X, y)\n",
    "\n",
    "# Now plotting our average y\n",
    "plt.hlines(y=y.mean(), # aka y_bar\n",
    "           xmin=X.min(), xmax=X.max(), \n",
    "           color='red',\n",
    "           label=f'Average Corn Stalk Height: {df[\"height\"].mean():.2f}')\n",
    "# Our errors/residuals are the distances between our actual and our predicted values\n",
    "plt.vlines(X, y, y.mean(), alpha=.5, color='gray', label=\"Our Errors aka How Wrong We'd Be\")\n",
    "\n",
    "plt.ylabel('Corn Stalk Height (cm)')\n",
    "plt.xlabel('Temperature (degrees F)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Those gray lines, the difference between the actual value and our average `y` value, have a special term when we sum and square them: that calculation of our error is called the **Total Sum of Squares**\n",
    "\n",
    "$$\\text{Total Sum of Squares} = \\sum\\limits_{i=1}^{200} (y_{i} - \\bar{y})^{2} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_bar = y.mean()\n",
    "\n",
    "TSS = sum((y - y_bar)**2)\n",
    "\n",
    "print(TSS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Beyond The Baseline\n",
    "\n",
    "But after we fit a linear regression line we have a better fit than just \"mean\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can use our model to grab our predicted values for y\n",
    "# Note that this bypasses needing to add the constant separately!\n",
    "y_pred = results.predict(sm.add_constant(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "# this plots the actual data\n",
    "plt.scatter(X, y)\n",
    "\n",
    "# this plots the 'best' line\n",
    "plt.plot(X, y_pred, label=\"Line of Best Fit\", color='black')\n",
    "# and this plots the 'average' line\n",
    "plt.hlines(y=y.mean(), \n",
    "           xmin=X.min(), xmax=X.max(), \n",
    "           color='red',\n",
    "           label=f'Average Corn Stalk Height: {df[\"height\"].mean():.2f}')\n",
    "\n",
    "plt.ylabel('Corn Stalk Height (cm)')\n",
    "plt.xlabel('Temperature (degrees F)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see this line is also not 'perfect' from prediction point of view. While our 'line of best fit' is a better fit than just guessing the average for y, there are still error terms - called **residuals**\n",
    "\n",
    "A **residual** is the difference between the actual value and the predicted value, aka how wrong we are!\n",
    "\n",
    "And, just like we calculated our Total Sum of Squares to understand how bad our dumb model-less baseline was, we can calculate our **Residual Sum of Squares** to understand how bad our line of best fit was.\n",
    "\n",
    "$$ \\text{Residual Sum of Squares (RSS)} = \\sum\\limits_{i=1}^{n} (y_i - \\text{y_pred}_{i})^{2}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "# this plots the actual data\n",
    "plt.scatter(X, y, label='Actual Values')\n",
    "\n",
    "# this plots the 'best' line\n",
    "plt.plot(X, y_pred, label=\"Line of Best Fit (Predicted Values)\", color='black')\n",
    "\n",
    "plt.vlines(X, y, y_pred, alpha=.5, color='gray', label='Residuals')\n",
    "\n",
    "plt.ylabel('Corn Stalk Height (cm)')\n",
    "plt.xlabel('Temperature (degrees F)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate our residuals\n",
    "residuals = y - y_pred\n",
    "\n",
    "# now sum the squared residuals\n",
    "RSS = sum(residuals**2)\n",
    "\n",
    "RSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Total Squared Sum is {TSS:.3f}')\n",
    "print(f'Residual Squared Sum is {RSS:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating R-Squared\n",
    "\n",
    "$R^{2}$ is just their ratio:\n",
    "\n",
    "$$ R^{2} = \\frac{TSS - RSS}{TSS} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R_squared = (TSS - RSS)/TSS\n",
    "\n",
    "R_squared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# can grab this straight from our results\n",
    "results.rsquared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is also given in the summary of results\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are three places I want you to look on this summary first, as you're getting used to this output!\n",
    "\n",
    "1. `R-Squared`\n",
    "2. `P>|t|`\n",
    "3. `coef`\n",
    "\n",
    "#### 1) `R-Squared`\n",
    "\n",
    "This shows your R2 score, and can tell you at a quick glance how well your model explains the variance in your target variable\n",
    "\n",
    "#### 2) `P>|t|`\n",
    "\n",
    "These P-values are calculated by statsmodels, and they tell you how likely it is that the impact the model found between the independent variable (or intercept) and the target is just due to random chance. That's right, we haven't ocmpletely left hypothesis testing in the dust: \"The p-value for each independent variable tests the null hypothesis that the variable has no correlation with the dependent variable.\" [[Source]](https://statisticsbyjim.com/regression/interpret-coefficients-p-values-regression/)\n",
    "\n",
    "#### 3) `coef`\n",
    "\n",
    "The coeficient captures the magnitude of the impact of the indepenedent variable on the target. \n",
    "\n",
    "We can look at this and, because we know `x1` here is our `temp` variable, we can say: \n",
    "> For every 1 degree increase in average temperature (in degrees F) across a corn plant's lifespan, we can expect a 4.5222cm increase in height by the time the corn stalk is fully grown.\n",
    "\n",
    "Our intercept is a bit different - that tells us what we'd expect our y-variable to measure if our independent variable is equal to zero. But... it's unlikely this is really the relationship - notice that the smallest temperature we have in our data is around 40 degrees F, nowhere close to zero. This is also why you'll hear me call the intercept a **_bias_** term - it's biasing our data, helping it to be a better model where our data actually is - but we should **NEVER** trust a model outside the bounds of our training data!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SUMMARY: Using `statsmodels`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use a simple dataset built into sklearn to recap what we've done so far:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in our data - note that it's built into this library, so a bit different\n",
    "from sklearn import datasets\n",
    "diabetes = datasets.load_diabetes(as_frame=True)\n",
    "\n",
    "# Our X here is a measurement of blood pressure\n",
    "# Our y is a numeric measure of diabetes progression\n",
    "X, y = diabetes.data['bp'], diabetes.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Process:\n",
    "# We first construct our model\n",
    "\n",
    "# We fit to learn the 'best' coefficients for intercept and slope\n",
    "\n",
    "# The summary method shows us many relevant statistics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate! How'd we do? What can we learn?\n",
    "\n",
    "- \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we want to find the equation for our line, we can look at our params\n",
    "intercept = None\n",
    "print(f\"Y-Intercept: {intercept}\")\n",
    "\n",
    "slope = None\n",
    "print(f\"Slope: {slope}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this prediction is nothing but:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"y = {slope:.3f} * X + {intercept:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "----\n",
    "\n",
    "# Level Up: Other Regression Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "What else do we have in this report?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- **F-statistic**: The F-test measures the significance of your model relative to a model in which all coefficients are 0, i.e. relative to a model that says there is no correlation whatever between the predictors and the target. <br/><br/>\n",
    "- **Log-Likelihood**: The probability in question is the probability of seeing these data points, *given* the model parameter values. The higher this is, the more our data conform to our model and so the better our fit. AIC and BIC are related to the log-likelihood; these are statistical measures of how well a model describes our data. <br/><br/>\n",
    "- **Omnibus**: This is a test for error normality. The probability is the chance that the errors are normally distributed. <br/><br/>\n",
    "- **Durbin-Watson**: This is a test for autocorrelation. We'll return to this topic in a future lecture. <br/><br/>\n",
    "- **Jarque-Bera**: This is another test for error normality. <br/><br/>\n",
    "- **Cond. No.**: The condition number tests for independence of the predictors. Lower scores are better. When the predictors are *not* independent, we can run into problems of multicollinearity. For more on the condition number, see [here](https://stats.stackexchange.com/questions/168259/how-do-you-interpret-the-condition-number-of-a-correlation-matrix)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Many good regression diagnostics are available in** [`statsmodels`](https://www.statsmodels.org/dev/examples/notebooks/generated/regression_diagnostics.html). For more on statsmodels regression statistics, see [here](https://www.accelebrate.com/blog/interpreting-results-from-linear-regression-is-the-data-appropriate)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Level Up: `sm.formula.ols()` (aka the lower case version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is an alternative way of using `statsmodels` to set up a linear regression, and that is with `sm.formula.ols()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sm.formula.ols(formula=\"height ~ temp\", data=df).fit().summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that this way of doing things *automatically sets up an intercept column*.\n",
    "\n",
    "That's an advantage, but this method has drawbacks inasmuch as the value for the `data` parameter has to have a certain structure. And in fact, once we start using train-test splits, our data will often *fail* to have that requisite structure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Level Up: Adjusted $R^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "There are some theoretical [objections](https://data.library.virginia.edu/is-r-squared-useless/) to using $R^2$ as an evaluator of a regression model.\n",
    "\n",
    "One objection is that, if we add another predictor to our model, $R^2$ can only *increase*! (It could hardly be that with more features I'd be able to account for *less* of the variation in the dependent variable than I could with the smaller set of features.)\n",
    "\n",
    "One improvement is **adjusted $R^2$**: <br/> $\\Large R^2_{adj.}\\equiv 1 - \\frac{(1 - R^2)(n - 1)}{n - m - 1}$, where:\n",
    "\n",
    "- n is the number of data points; and\n",
    "- m is the number of predictors.\n",
    "\n",
    "This can be a better indicator of the quality of a regression model. For more, see [here](https://www.statisticshowto.datasciencecentral.com/adjusted-r2/).\n",
    "\n",
    "Note that Adjusted $R^2$ *can* be negative!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "TOC",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "288px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
