{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transforming Data and Dealing with Categorical Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding Categorical Variables, Normalizing Variables, Incorporating Interaction and Polynomial Terms, ETC\n",
    "\n",
    "\n",
    "Today's focus is all about translating raw **data** into useful **information** that a model can understand and properly use. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Up\n",
    "\n",
    "New dataset for today! Insurance costs\n",
    "\n",
    "My source: https://www.kaggle.com/mirichoi0218/insurance (they got the idea for cleaning up the original open source data from [Machine Learning with R](https://www.packtpub.com/product/machine-learning-with-r-third-edition/9781788295864))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/insurance.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# explore the data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize relationships between numeric columns\n",
    "sns.pairplot(df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# visualize correlations between numeric columns\n",
    "sns.heatmap(df.corr(), annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial Model!\n",
    "\n",
    "Let's run a kitchen sink model! Ignoring categorical columns, let's just throw all of our numeric columns into a model and see how we do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set our X and y\n",
    "# ignore our categorical columns for now\n",
    "used_cols = None\n",
    "X = None\n",
    "y = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=0.25, \n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale our data\n",
    "\n",
    "# fit scaler on train data\n",
    "\n",
    "# transform both train and test data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now, let's model!\n",
    "lr_base = None\n",
    "\n",
    "# grab predictions for train and test set\n",
    "train_preds = None\n",
    "test_preds = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate\n",
    "print(f\"Train R2 Score: {r2_score(y_train, train_preds):.3f}\")\n",
    "print(f\"Test R2 Score: {r2_score(y_test, test_preds):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's look at our residuals\n",
    "# for our full model\n",
    "plt.scatter(train_preds, y_train-train_preds, label='Train')\n",
    "plt.scatter(test_preds, y_test-test_preds, label='Test')\n",
    "\n",
    "plt.axhline(y=0, color = 'red', label = '0')\n",
    "plt.xlabel('predictions')\n",
    "plt.ylabel('residuals')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate: How'd we do? What do you notice?\n",
    "\n",
    "- \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding Categorical Variables\n",
    "\n",
    "How do we bring in those categorical columns? By **encoding** them - translating the string variables into useful numbers the model can hopefully understand and take meaning from."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Most Common Encoding Method: One Hot Encoding (OHE)\n",
    "\n",
    "One very effective way of dealing with categorical variables is to dummy them out, a process also known as One Hot Encoding. What this involves is making a new column for _each categorical value_ in the column we're dummying out.\n",
    "\n",
    "These new columns are turned into binaries, with a 1 representing the presence of the relevant categorical value.\n",
    "\n",
    "\n",
    "For an example in our data: we have a column called `region`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['region'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['region'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With OHE, the result will either be three or four new columns: `is_southeast`, `is_northwest`, `is_southwest`, `is_northeast`\n",
    "\n",
    "For the head of this data:\n",
    "\n",
    "| `is_southeast` | `is_northwest` | `is_southwest` | `is_northeast` |\n",
    "| -------------- | -------------- | -------------- | -------------- | \n",
    "| 0 | 0 | 1 | 0 |\n",
    "| 1 | 0 | 0 | 0 |\n",
    "| 1 | 0 | 0 | 0 |\n",
    "| 0 | 1 | 0 | 0 |\n",
    "| 0 | 1 | 0 | 0 |\n",
    "\n",
    "Why could this result in three columns instead of four? We often drop the first column, and allow the model to capture that value by having zeros in all other columns. This reduces the **multicollinearity** between these newly created columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll explore two methods to one hot encode our features: a pandas method, which is easy but does not allow for the same transformation on both train and test, and a sklearn method, which learns the patterns and can then later transform test in the same way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### With Pandas' `get_dummies()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Let's look at the columns we have\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's define a list of our categorical columns\n",
    "cat_cols = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And a list of our full X columns\n",
    "# Fun trick!\n",
    "x_cols = [*used_cols, *cat_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot encode variables\n",
    "df_ohe = pd.get_dummies(df[x_cols], # note that we run it on all X cols\n",
    "                        columns=cat_cols, # but only encode cat cols\n",
    "                        drop_first=True) # drop first for multicollinearity\n",
    "print(df_ohe.shape)\n",
    "df_ohe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### With `sklearn`'s One Hot Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's import two things from SKLearn that will make encoding these columns easy\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-define our X value to include ALL columns\n",
    "X = df[x_cols]\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New train-test split for the new X\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=0.25, \n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an encoder object. This will help us to convert\n",
    "# categorical variables to new columns\n",
    "encoder = OneHotEncoder(handle_unknown='error',\n",
    "                        drop='first',\n",
    "                        categories='auto')\n",
    "\n",
    "# Create an columntransformer object.\n",
    "# This will help us to merge transformed columns\n",
    "# with the rest of the dataset.\n",
    "ct = ColumnTransformer(transformers=[('ohe', encoder, cat_cols)],\n",
    "                       remainder='passthrough')\n",
    "ct.fit(X_train)\n",
    "X_train_enc = ct.transform(X_train)\n",
    "X_test_enc = ct.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# can display as a dataframe like so\n",
    "pd.DataFrame(X_train_enc, columns= ct.get_feature_names()).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale our data - now let's use a Min Max Scaler because binaries!\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# train on train data\n",
    "scaler.fit(X_train_enc)\n",
    "\n",
    "# transform both train and test data\n",
    "X_train_scaled = scaler.transform(X_train_enc)\n",
    "X_test_scaled = scaler.transform(X_test_enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now, let's model!\n",
    "lr_ohe = None\n",
    "\n",
    "# grab predictions for train and test set\n",
    "train_preds = None\n",
    "test_preds = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate\n",
    "print(f\"Train R2 Score: {r2_score(y_train, train_preds):.3f}\")\n",
    "print(f\"Test R2 Score: {r2_score(y_test, test_preds):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize residuals, for the model that now has cat cols\n",
    "plt.scatter(train_preds, y_train-train_preds, label='Train')\n",
    "plt.scatter(test_preds, y_test-test_preds, label='Test')\n",
    "\n",
    "plt.axhline(y=0, color = 'red', label = '0')\n",
    "plt.xlabel('predictions')\n",
    "plt.ylabel('residuals')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate: Thoughts?\n",
    "\n",
    "- \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Some Pros and Cons of OHE:\n",
    "\n",
    "Pros:\n",
    "\n",
    "- Simple to understand\n",
    "- Easy to implement\n",
    "\n",
    "Cons:\n",
    "\n",
    "- If the categorical column has many options, or there are a lot of categorical columns, you can add _a lot_ more columns - **curse of dimensionality**\n",
    "- Resulting columns are very sparse (mostly zeros)\n",
    "- Resulting columns are directly related (multicollinear)\n",
    "\n",
    "Also - how do we interpret these coefficients?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the coefs from our sklearn model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how the model now includes parameters for our dummies! But here's a question: How do we **interpret** them?\n",
    "\n",
    "In the case of `age`, we have a beta of 3643.065, and that means that we can expect the insurance charges to grow by 3643.065 if we increase the person's age by one unit (here, one percent because we min-max scaled our X variables).\n",
    "\n",
    "But take the beta for `ohe__x1_yes` - where x1 means 'smoker'. The value there is 9546.251. How can we understand this? \n",
    "\n",
    "This value encodes the difference we can expect in our target (charges) when we *increase the variable by one unit*. But for this variable, \"increasing it by one unit\" means going from `ohe__x1_yes=0` to `ohe__x1_yes=1`, and *that* means going from a person who doesn't smoke to one who does! So it's critical always to keep in mind when interpreting the coefficients of categorical variables in a linear regression model that they must be interpreted against a **baseline**, which is where the values of the inputs are 0. Notice that, for the same reason, this also affects the interpretation of the intercept term.\n",
    "\n",
    "More practice/resources: https://github.com/hoffm386/coefficients-of-dropped-categorical-variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other Encoding Methods?\n",
    "\n",
    "Certainly there are other ways to turn a categorical column into numeric data that a model can understand.\n",
    "\n",
    "Some Examples:\n",
    "\n",
    "- [Label/Ordinal Encoding](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OrdinalEncoder.html)\n",
    "- [Frequency Encoding](https://contrib.scikit-learn.org/category_encoders/count.html) (just a count encoder with `normalize=True` to turn into a frequency percentage)\n",
    "- [Target Encoding](https://contrib.scikit-learn.org/category_encoders/targetencoder.html) (or, relatedly, [Leave-One-Out Encoding](https://contrib.scikit-learn.org/category_encoders/leaveoneout.html) or [Weight of Evidence Encoding](https://contrib.scikit-learn.org/category_encoders/woe.html))\n",
    "\n",
    "Useful links:\n",
    "\n",
    "- [Category Encoders](https://contrib.scikit-learn.org/category_encoders/index.html) - library of sklearn-style encoders that implement more encoding methods than those actually packaged in Sklearn\n",
    "- [Sklearn's Preprocessing Section](https://scikit-learn.org/stable/modules/preprocessing.html#preprocessing) - user guide section on preprocessing (includes scalers and transformers as well as encoders)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribution Transformations - AKA Normalizing Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear regression can work better if the predictor and target are normally distributed. \n",
    "\n",
    "**Log-scaling** can be a good tool to make *right-skewed* data more normal.\n",
    "\n",
    "(For *left-skewed* data, which is rarer, we can try transforming our data by raising it to an exponent greater than 1.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose e.g. a kde plot of my predictor $X$ looks like this:\n",
    "\n",
    "![original](images/skewplot.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In that case, the kde plot of a log-transformed version of $X$ could look like this:\n",
    "\n",
    "![log](images/logplot.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at our `y` value - how is it distributed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.hist();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's pretty skewed! Let's see what transforming it would look like.\n",
    "\n",
    "Log transformation using numpy - [documentation](https://numpy.org/doc/stable/reference/generated/numpy.log.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.log(y).hist();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Much more normal!\n",
    "\n",
    "Let's log both our train and test y, then see if our model improves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_log = None\n",
    "y_test_log = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now, let's model!\n",
    "lr_log = None\n",
    "\n",
    "# grab predictions for train and test set\n",
    "train_preds = None\n",
    "test_preds = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate\n",
    "print(f\"Train R2 Score: {r2_score(y_train_log, train_preds):.3f}\")\n",
    "print(f\"Test R2 Score: {r2_score(y_test_log, test_preds):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize residuals, for the model of log-y\n",
    "plt.scatter(train_preds, y_train_log-train_preds, label='Train')\n",
    "plt.scatter(test_preds, y_test_log-test_preds, label='Test')\n",
    "\n",
    "plt.axhline(y=0, color = 'red', label = '0')\n",
    "plt.xlabel('predictions')\n",
    "plt.ylabel('residuals')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate - Thoughts?\n",
    "\n",
    "- \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpreting after Log Transformations\n",
    "\n",
    "But with this transformed target, how do I now interpret my LR coefficients?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Look at coefs for our ohe model\n",
    "dict(zip(ct.get_feature_names(), lr_ohe.coef_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Now for coefs of our log model\n",
    "dict(zip(ct.get_feature_names(), lr_log.coef_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before the transformation, I would have said that a one-unit increase (and note - units are standard deviations because we scaled our X inputs!) in `age` results on average in a 3643.065 increase in `charges`. \n",
    "\n",
    "But what I need to say now is that a one-unit increase in `age` results on average in a 0.486 increase *in the logarithm of price*, i.e. an increase in price by a factor of $e^{0.486}$.\n",
    "\n",
    "More practically, you can interpret the exponent as a percentage! If you take the exponent of the coefficient minus one, that gives you the percentage increase.\n",
    "\n",
    "Formula:\n",
    "\n",
    "$e ^ \\text{coef} - 1$\n",
    "\n",
    "In code:\n",
    "```\n",
    "(np.exp(coef) - 1) * 100\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# For example:\n",
    "log_coef_dict = dict(zip(ct.get_feature_names(), lr_log.coef_))\n",
    "\n",
    "for feature, coef in log_coef_dict.items():\n",
    "    print(f\"A One-Unit Increase in {feature} results on average in a {(np.exp(coef) - 1) * 100}% change in charges\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that our binary columns start to get really weird. In practice, before interpreting variables in any practical sense, we'd run one last model without scaling to allow us to better interpret our results - but we'll still likely keep our logged `y` as our target if it improves our model!\n",
    "\n",
    "Reference:\n",
    "- https://stats.oarc.ucla.edu/sas/faq/how-can-i-interpret-log-transformed-variables-in-terms-of-percent-change-in-linear-regression/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
